{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import statistics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '../Data/SNV_filtering_inputs/PillarProject_filtering/PALB2/20250822_PALB2_PillarProjectRef.xlsx' #path to annotated reference file (you will need to manually give coordinates for where exons are). I originally downloaded the sequence from benchling\n",
    "sge_scores = '../Data/SNV_filtering_inputs/PillarProject_filtering/PALB2/20250825.PALB2.snvscores.tsv'  #path to SGE datafile\n",
    "gene = 'PALB2' #name of your gene :)\n",
    "ref_sense = 0 #Sense of the reference file you provide\n",
    "filtered_file_name = '../Data/SNV_filtering_inputs/PillarProject_filtering/PALB2/20250825_PALB2snvscores_filtered.xlsx' #name of saved file\n",
    "targets_input = '../Data/SNV_filtering_inputs/PillarProject_filtering/PALB2/20250825_PALB2_targets.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reverse_complement_string(seq_string): #Reverse complement and returns string\n",
    "    reverse_seq = seq_string[::-1]\n",
    "    reverse_comp_list = []\n",
    "    for char in reverse_seq:\n",
    "        if char == \"A\":\n",
    "            reverse_comp_list.append(\"T\")\n",
    "        elif char == \"G\":\n",
    "            reverse_comp_list.append(\"C\")\n",
    "        elif char == \"C\":\n",
    "            reverse_comp_list.append(\"G\")\n",
    "        else:\n",
    "            reverse_comp_list.append(\"A\")\n",
    "    reverse_compliment_str = \"\".join(reverse_comp_list)\n",
    "    return reverse_compliment_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def mutate_snvs(dna_sequence): #Mutates all possible SNVs of provided DNA sequence\n",
    "    snvs = []\n",
    "    i = 0\n",
    "    while i < len(dna_sequence):\n",
    "        if dna_sequence[i] == \"A\":\n",
    "            snvs.append(dna_sequence[:i] + \"T\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"C\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"G\" + dna_sequence[i + 1 :])\n",
    "        elif dna_sequence[i] == \"T\":\n",
    "            snvs.append(dna_sequence[:i] + \"A\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"C\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"G\" + dna_sequence[i + 1 :])\n",
    "        elif dna_sequence[i] == \"C\":\n",
    "            snvs.append(dna_sequence[:i] + \"A\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"T\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"G\" + dna_sequence[i + 1 :])\n",
    "        else:\n",
    "            snvs.append(dna_sequence[:i] + \"A\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"T\" + dna_sequence[i + 1 :])\n",
    "            snvs.append(dna_sequence[:i] + \"C\" + dna_sequence[i + 1 :])\n",
    "        i += 1\n",
    "    return snvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def string_compare(string1, string2):\n",
    "    if len(string1) != len(string2):\n",
    "        print(len(string1), len(string2))\n",
    "        print('String1: ', string1, ' ', 'String2: ', string2)\n",
    "        raise ValueError('Different Length Strings')\n",
    "\n",
    "    else:\n",
    "        i = 0\n",
    "        while i < len(string1):\n",
    "            char = string1[i]\n",
    "            if char == string2[i]:\n",
    "                i += 1\n",
    "            else:\n",
    "                return i, char\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def identify_same_codon(numbers):\n",
    "    pairs = []\n",
    "    for i in range(len(numbers)):\n",
    "        for j in range(i + 1, len(numbers)):\n",
    "            if abs(numbers[i] - numbers[j]) == 2:\n",
    "                pairs.append([numbers[i], numbers[j]])\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_inputs(reference, sge, targets):\n",
    "    reference = pd.read_excel(reference)\n",
    "    reference['Reference'] = reference['Reference'].transform(lambda x: x.upper())\n",
    "    raw_data = pd.read_csv(sge, sep = '\\t')\n",
    "    targets = pd.read_csv(targets, sep = '\\t')\n",
    "\n",
    "    sge_targets = list(set(raw_data['target'].tolist()))\n",
    "    print(sge_targets)\n",
    "\n",
    "    targets = targets.loc[targets['target'].isin(sge_targets)]\n",
    "    targets = targets.reset_index(drop = True)\n",
    "    print(targets)\n",
    "    return reference, raw_data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edits(df):\n",
    "    \n",
    "    i = 0\n",
    "    edits_dict = {}\n",
    "    while i < len(df):\n",
    "        target = df['target'][i]\n",
    "        all_edits = df['required_edits'][i]\n",
    "        edits_split = all_edits.split(',')\n",
    "        \n",
    "        edits_dict[target] = edits_split\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return edits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(edit_dict, data, ref, sense):\n",
    "\n",
    "    grouped = data.groupby('target')\n",
    "\n",
    "    to_filter = []\n",
    "    for target, df in grouped:\n",
    "        target_ref = ref.loc[ref['target'].isin([target])]\n",
    "        edits = edit_dict[target]\n",
    "        edits_split = {int(s[:-1]): s[-1] for s in edits}\n",
    "\n",
    "        edit_pos = list(edits_split.keys())\n",
    "        same_codon = identify_same_codon(edit_pos)\n",
    "        \n",
    "        if len(same_codon) > 0:\n",
    "            pos_to_remove = str(statistics.median(same_codon))\n",
    "            to_remove = [pos_to_remove + ':' + 'A',\n",
    "                         pos_to_remove + ':' + 'T',\n",
    "                         pos_to_remove + ':' + 'G',\n",
    "                         pos_to_remove + ':' + 'C'\n",
    "                        ]\n",
    "            print('Doubles: ', pos_to_remove)\n",
    "        for pos in edit_pos:\n",
    "            if sense == 0:\n",
    "                edited_codon_coords = list(range(pos, pos + 3))\n",
    "                \n",
    "                print('1 - ', edited_codon_coords)\n",
    "                \n",
    "                wt_codon_df = target_ref.loc[target_ref['pos'].isin(edited_codon_coords)]\n",
    "                wt_codon = wt_codon_df['Reference'].tolist()\n",
    "                wt_codon = ''.join(wt_codon)\n",
    "                wt_codon = reverse_complement_string(wt_codon)\n",
    "                print(\"WT\", wt_codon)\n",
    "\n",
    "                if len(wt_codon) != 3:\n",
    "                    warnings.warn('Incomplete Codon')\n",
    "                    error_string = 'Incomplete Codon at pos ' + str(pos)\n",
    "                    print(error_string)\n",
    "                    continue\n",
    "                    \n",
    "                canonical_snvs = mutate_snvs(wt_codon)\n",
    "                possible_aa = []\n",
    "                \n",
    "                for elem in canonical_snvs:\n",
    "                    var = Seq(elem)\n",
    "                    aa = var.translate()\n",
    "                    possible_aa.append(str(aa))\n",
    "\n",
    "                mut_codon = wt_codon[0:2] + reverse_complement_string(edits_split[pos])\n",
    "                fixed_edit = reverse_complement_string(edits_split[pos])\n",
    "                mut_codon = wt_codon[0:2]\n",
    "                mut_snvs = mutate_snvs(mut_codon)\n",
    "\n",
    "                fixed_edit_aa = []\n",
    "                impossible = []\n",
    "                \n",
    "                for elem in mut_snvs:\n",
    "                    full_mut_codon = elem + fixed_edit\n",
    "                    \n",
    "                    normalized_pos, mut_codon_snv = string_compare(full_mut_codon[0:2], wt_codon[0:2])\n",
    "                    if normalized_pos == 0:\n",
    "                        mut_codon_pos = pos + 2\n",
    "                    elif normalized_pos == 1:\n",
    "                        mut_codon_pos = pos + 1\n",
    "\n",
    "                    print('mut codon', full_mut_codon, mut_codon_pos, normalized_pos)\n",
    "                    mut_codon_pos_id = str(mut_codon_pos) + ':' + reverse_complement_string(mut_codon_snv)\n",
    "\n",
    "                    var = Seq(full_mut_codon)\n",
    "                    aa = str(var.translate())\n",
    "                    fixed_edit_aa.append(aa)\n",
    "                    if aa in possible_aa:\n",
    "                        continue\n",
    "                    else:\n",
    "                        impossible.append(aa)\n",
    "                        to_filter.append(mut_codon_pos_id)\n",
    "                                         \n",
    "                print('2 - ', target, pos, possible_aa, fixed_edit_aa, impossible)\n",
    "                print('3 - ', len(impossible), len(to_filter))\n",
    "\n",
    "            elif sense == 1:\n",
    "                edited_codon_coords = list(range(pos - 3, pos))\n",
    "                \n",
    "                print('1 - ', edited_codon_coords)\n",
    "                \n",
    "                wt_codon_df = target_ref.loc[target_ref['pos'].isin(edited_codon_coords)]\n",
    "                wt_codon = wt_codon_df['Reference'].tolist()\n",
    "                wt_codon = ''.join(wt_codon)\n",
    "\n",
    "                canonical_snvs = mutate_snvs(wt_codon)\n",
    "                possible_aa = []\n",
    "                \n",
    "                for elem in canonical_snvs:\n",
    "                    var = Seq(elem)\n",
    "                    aa = var.translate()\n",
    "                    possible_aa.append(str(aa))\n",
    "\n",
    "                mut_codon = wt_codon[0:2] + (edits_split[pos])\n",
    "                fixed_edit = edits_split[pos]\n",
    "                mut_codon = wt_codon[0:2]\n",
    "                mut_snvs = mutate_snvs(mut_codon)\n",
    "\n",
    "                fixed_edit_aa = []\n",
    "                impossible = []\n",
    "                \n",
    "                for elem in mut_snvs:\n",
    "                    full_mut_codon = elem + fixed_edit\n",
    "                    normalized_pos, mut_codon_snv = string_compare(full_mut_codon[0:2], wt_codon[0:2])\n",
    "                    if normalized_pos == 0:\n",
    "                        mut_codon_pos = pos - 2\n",
    "                    elif normalized_pos == 1:\n",
    "                        mut_codon_pos = pos -1\n",
    "                        \n",
    "                    print('mut codon', full_mut_codon, mut_codon_pos, normalized_pos)\n",
    "                    mut_codon_pos_id = str(mut_codon_pos) + ':' + mut_codon_snv\n",
    "\n",
    "                    var = Seq(full_mut_codon)\n",
    "                    aa = str(var.translate())\n",
    "                    fixed_edit_aa.append(aa)\n",
    "                    if aa in possible_aa:\n",
    "                        continue\n",
    "                    else:\n",
    "                        impossible.append(aa)\n",
    "                        to_filter.append(mut_codon_pos_id)\n",
    "                                         \n",
    "                print('2 - ', target, pos, possible_aa, fixed_edit_aa, impossible)\n",
    "                print('3 - ', len(impossible), len(to_filter))\n",
    "    \n",
    "\n",
    "    return to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(sge, to_filter):\n",
    "\n",
    "    sge['pos'] = sge['pos'].astype(str)\n",
    "    sge['pos_id'] = sge['pos'] + ':' + sge['alt']\n",
    "    sge['pos'] = sge['pos'].astype(int)\n",
    "\n",
    "    filtered = sge.loc[~((sge['pos_id'].isin(to_filter)) & (sge['amino_acid_change'] != '---'))]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ref, raw_data, targets = read_inputs(ref_path, sge_scores, targets_input)\n",
    "    all_edits = get_edits(targets)\n",
    "    to_filter = filter(all_edits, raw_data, ref, ref_sense)\n",
    "    filtered_data = filter_data(raw_data, to_filter)\n",
    "\n",
    "\n",
    "    filtered_data.to_excel(filtered_file_name, index = False)\n",
    "    print(to_filter)\n",
    "    print('Filtering statistics: ', '\\n',\n",
    "            'RAW DATA: ', len(raw_data), '\\n',\n",
    "           'VARS. TO FILTER: ', len(to_filter), '\\n',\n",
    "            'POST FILTER: ', len(filtered_data), '\\n'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
