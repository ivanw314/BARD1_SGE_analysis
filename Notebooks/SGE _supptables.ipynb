{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_file = '../Data/20250829_BARD1delscores.tsv'\n",
    "snv_file = '../Data/20250825_BARD1snvscores_filtered.xlsx'\n",
    "clinvar_snvs_file = '../Data/20250912_BARD1_ClinVarSNVs_1StarPlus.txt'\n",
    "clinvar_dels_file = '../Data/20250912_BARD1_ClinVarDels_1StarPlus.txt'\n",
    "gnom_path = '../Data/20240905_BARD1_gnomADv4.1.0_SNVs.xlsx' #gnomAD data path\n",
    "reg_path = '../Data/20240802_BARD1_Regeneron_MAF.xlsx' #Regeneron data path\n",
    "rna_scores = ''\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Functions for initial read in of SGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(thresholds): #Gets SGE thresholds\n",
    "    df = pd.read_excel(thresholds)\n",
    "\n",
    "    # find the GMM thresholds\n",
    "    target_value = 0.950\n",
    "    # Calculate the absolute difference for the Normal (N) density\n",
    "    diffN = (df['gmm_density_normal'] - target_value).abs()\n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = diffN.idxmin()\n",
    "    # Retrieve the row with the closest value\n",
    "    closest_row_n = df.loc[closest_index]\n",
    "    \n",
    "    # now repeat that for the abnormal density\n",
    "    # Calculate the absolute difference\n",
    "    diffA = (df['gmm_density_abnormal'] - target_value).abs()\n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = diffA.idxmin()\n",
    "    # Retrieve the row with the closest value\n",
    "    closest_row_a = df.loc[closest_index]\n",
    "    \n",
    "    # now we get the scores that are the closest to the (n)ormal and (a)bnormal thresholds\n",
    "    uppr = closest_row_n['score']\n",
    "    lwr = closest_row_a['score']\n",
    "    \n",
    "    thresholds = [lwr, uppr]\n",
    "\n",
    "    \n",
    "    #Some quick processing of SNV scores\n",
    "    df.loc[df['score'] >= 0, 'functional_consequence'] = 'functionally_normal' #Ensures that variants above our upper threshold (which is less than 0) will be assigned a functionally normal class\n",
    "    df['var_type'] = 'snv' #Sets variant type column to SNV\n",
    "    df = df.drop(columns = ['functional_consequence_zscore', 'gmm_density_abnormal', 'gmm_density_normal', 'target_pos_id', 'gmm_consequence_0.99']) #Drops these columns\n",
    "                 \n",
    "    return df, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_dels(dels, thresholds):\n",
    "    dels = pd.read_csv(dels, sep = '\\t') #Reads deletions\n",
    " \n",
    "    dels['functional_consequence'] = 'indeterminate' #Sets base functional consequence to indeterminate\n",
    "    dels.loc[dels['score'] <= thresholds[0], 'functional_consequence'] = 'functionally_abnormal' #Dels scoring below or equal to lower threshold are functionally abnormal\n",
    "    dels.loc[dels['score'] >= thresholds[1], 'functional_consequence'] = 'functionally_normal' #Dels scoring at or above to upper threshold are functionally normal\n",
    "    dels['var_type'] = '3bp_del'\n",
    "    dels['pos_id'] = dels['start'].astype(str) + '-' + dels['end'].astype(str)\n",
    "\n",
    "    return dels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Functions used to process and merge the ClinVar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clinvar(snv_file, del_file): #Reads ClinVar data\n",
    "    \n",
    "    df = pd.read_csv(snv_file, delimiter='\\t') #reads ClinVar SNV tabular .txt \n",
    "    df = df[['Name','Protein change','GRCh38Chromosome','GRCh38Location','Germline classification']] #pulls useful columns\n",
    "    df = df.dropna(subset = ['GRCh38Location']) #Drops variants without genomic coordinate\n",
    "    df.GRCh38Location = df.GRCh38Location.astype(int) #Sets coordinates to integer data type\n",
    "    df['pos_id'] = None #preps for next function\n",
    "\n",
    "\n",
    "    del_df = pd.read_csv(del_file, sep = '\\t') #Reads ClinVar deletions\n",
    "    del_df = del_df.loc[del_df['GRCh38Location'].str.contains('-')] #Splits coordinates\n",
    "    del_df['start'] = del_df['GRCh38Location'].transform(lambda x: x.split(' - ')[0]) #Gets deletion start coordinate\n",
    "    del_df['end'] = del_df['GRCh38Location'].transform(lambda x: x.split(' - ')[1]) #Gets deletion end coordinate\n",
    "\n",
    "    #Sets coordinate data types to integer\n",
    "    del_df['start'] = del_df['start'].astype(int) \n",
    "    del_df['end'] = del_df['end'].astype(int)\n",
    "\n",
    "    del_df['del_length'] = del_df['end'] - del_df['start'] #Calculates deletion length \n",
    "\n",
    "    del_df = del_df.loc[del_df['del_length'].isin([2])] #Pulls out 3bp deletions\n",
    "    del_df['pos_id'] = del_df['start'].astype(str) + '-' + del_df['end'].astype(str) #Sets base change column to coordinate spanned by deletion\n",
    "    del_df = del_df[['pos_id', 'Germline classification']] #Pulls out necessary columns\n",
    "\n",
    "\n",
    "    return df, del_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair(base): #ClinVar gives base changes on negative sense strand, SGE pos_id on positive sense\n",
    "    if base == 'A':\n",
    "        return 'T'\n",
    "    elif base == 'T':\n",
    "        return 'A'\n",
    "    elif base == 'C':\n",
    "        return 'G'\n",
    "    else:\n",
    "        return 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_changes(df): #Creates pos_id column in format of SGE datafile for ClinVar data    \n",
    "    k = 0\n",
    "    while k < len(df):\n",
    "        var = df['Name'][k]\n",
    "        coord = str(df['GRCh38Location'][k])\n",
    "        k += 1\n",
    "        i = 0\n",
    "        j = 3\n",
    "        while j < (len(var) + 1):\n",
    "            test_str = var[i:j]\n",
    "            j += 1\n",
    "            i += 1\n",
    "            sense_base = get_pair(test_str[2])\n",
    "            if test_str[1] == '>':\n",
    "                change = coord + \":\" + sense_base\n",
    "                df.loc[df['Name'] == var, 'pos_id'] = change\n",
    "                \n",
    "    df = df[['pos_id', 'Germline classification']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Functions used to merge allele frequency data from gnomAD and Regeneron Million Exomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gnomAD(gnomAD_path): #Reads gnomAD file\n",
    "    \n",
    "    unfiltered = pd.read_excel(gnomAD_path) #Reads gnomAD file\n",
    "    filtered = unfiltered[['gnomAD ID', 'Allele Frequency']] #Gets necessary columns \n",
    "\n",
    "    filtered = filtered.copy()\n",
    "    filtered['pos_id'] = filtered['gnomAD ID'].transform(lambda x: x[2:11] + ':' + x[14]) #Adds pos_id column for merging\n",
    "\n",
    "    filtered = filtered.rename(columns = {'Allele Frequency': 'gnomad_af'})\n",
    "    filtered = filtered[['pos_id', 'gnomad_af']]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_regeneron(reg_path): #Reads Regeneron data\n",
    "    \n",
    "    df = pd.read_excel(reg_path) #Reads data\n",
    "    maf = df[['Variant','AAF']] #Pulls necessary columns\n",
    "    maf = maf.copy()\n",
    "\n",
    "    maf = maf.rename(columns = {'AAF': 'regeneron_maf', 'Variant': 'pos_id'}) #Renames columns to share column names with SGE data\n",
    "\n",
    "    maf['pos_id'] = maf['pos_id'].transform(lambda x: x[2:12] + x[len(x) - 1: len(x) + 1]) #Remakes the pos_id column to match pos_id column from SGE data for merging\n",
    "    \n",
    "    return maf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    #Reads SGE data\n",
    "    snv_df, snv_thresholds = get_thresholds(snv_file)\n",
    "    del_df = class_dels(del_file, snv_thresholds)\n",
    "\n",
    "    sge_df = pd.concat([snv_df, del_df]) #Final concatenated SNVs and Deletions dataframe\n",
    "\n",
    "    #Processes and Merges ClinVar Data\n",
    "    clinvar_snvs, clinvar_dels = read_clinvar(clinvar_snvs_file, clinvar_dels_file)\n",
    "    clinvar_snvs = get_base_changes(clinvar_snvs)\n",
    "    all_clinvar = pd.concat([clinvar_snvs, clinvar_dels])\n",
    "    \n",
    "    df = pd.merge(sge_df, all_clinvar, on = 'pos_id', how = 'left') #df merged with ClinVar\n",
    "\n",
    "    #Processes and Merges MAF Data\n",
    "    gnomad_df = read_gnomAD(gnom_path)\n",
    "    regeneron_df = read_regeneron(reg_path)\n",
    "\n",
    "    df = pd.merge(df, gnomad_df, on = 'pos_id', how = 'left')\n",
    "    df = pd.merge(df, regeneron_df, on = 'pos_id', how = 'left')\n",
    "\n",
    "    threshold_df = pd.DataFrame({'min': [snv_thresholds[0]], 'max': [snv_thresholds[1]]})\n",
    "\n",
    "    dfs = {'scores': df,\n",
    "           'thresholds': threshold_df\n",
    "          }\n",
    "    print(df)\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter('../Data/BARD1_SGE_final_table.xlsx') as writer:\n",
    "        for sheet_name, df in dfs.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
