{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook builds figure 3D (odds ratio plot) and the odds ratio supplmentary table. Notebook also requires external case-control cohort data that must be provided in addition to the final data table Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sge = '../Data/final_tables/BARD1_SGE_final_table.xlsx' #sge data tables\n",
    "\n",
    "#External case-control data\n",
    "carriers = '../Data/case_control_data/CARRIERS_data/20250303_CARRIERS_data.xlsx' #carriers data\n",
    "bridges_all = '../Data/case_control_data/BRIDGES_data/20250815_BRIDGES_missense_all.xlsx' #bridges all missense variants\n",
    "bridges_population = '../Data/case_control_data/BRIDGES_data/20250815_BRIDGES_missense_population.xlsx' #bridges population missense variants\n",
    "bridges_all_ptv = '../Data/case_control_data/BRIDGES_data/20250815_BRIDGES_PTVs_all.xlsx' #bridges all PTVs\n",
    "bridges_pop_ptv = '../Data/case_control_data/BRIDGES_data/20250815_BRIDGES_PTVs_pop.xlsx' #bridges population PTVs\n",
    "\n",
    "\n",
    "#Total individuals sequenced for CARRIERS and BRIDGES studies.\n",
    "#All denotes all individuals/patients sequenced by the study. 'pop' denotes the subset found in patients without considering family history of breast cancer\n",
    "carriers_totals = {'cases_all': 39553, #Total number of cases sequenced\n",
    "                   'controls_all': 35867, #Total number of controls sequenced\n",
    "                   'cases_pop': 32247, #Nubmer of cases used for population-based estimates\n",
    "                   'controls_pop': 32544, #Number of controls used for population-based estimates\n",
    "                   'er_cases': 3805 #Number of estrogen receptor (ER) negative cases used in population-based estimates\n",
    "                  }\n",
    "\n",
    "#Annotations for are same, but numbers are pulled from the BRIDGES study\n",
    "bridges_totals = {'cases_all': 60466, \n",
    "                  'controls_all': 53461,\n",
    "                  'cases_pop': 48826,\n",
    "                  'controls_pop': 50703\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sge(sge): #Reads SGE data\n",
    "    \n",
    "    sge = pd.read_excel(sge, sheet_name = 'scores') #Reads SGE data\n",
    "    sge = sge.loc[~sge['variant_qc_flag'].isin(['WARN'])] #Removes 'WARN' variants\n",
    "    sge = sge.loc[sge['var_type'].isin(['snv'])] #Filters for SNVs only\n",
    "    \n",
    "    sge = sge.loc[~(sge['functional_consequence'].isin(['indeterminate']))] #Removes variants with indeterminate functional classification\n",
    "\n",
    "    sge = sge.rename(columns = {'functional_consequence': 'Classification', \n",
    "                               'consequence': 'Consequence'}) #Renames for downstream code\n",
    "\n",
    "    #Creates classifcation column based on SGE function class\n",
    "    sge.loc[sge['Classification'] == 'functionally_normal', 'Classification'] = 'F'\n",
    "    sge.loc[sge['Classification'] == 'functionally_abnormal', 'Classification'] = 'NF'\n",
    "\n",
    "    \n",
    "    sge_all = sge \n",
    "    \n",
    "    sge_miss = sge[sge['Consequence'].isin(['missense_variant'])] #missense variants only \n",
    "    sge_miss = sge_miss.copy()\n",
    "    sge_miss['AApos'] = sge_miss['amino_acid_change'].str.extract(r'([0-9]+)', expand=False).astype(int) #Makes column for amino acid position for subsetting on BARD1 region\n",
    "\n",
    "    '''\n",
    "    not_domain_coords = list(range(1, 26)) + list(range(123, 425)) + list(range(546, 568))\n",
    "    sge_ring = sge_miss.loc[sge_miss['AApos'].isin(list(range(26,123)))] #RING missense variants only\n",
    "    sge_ard = sge_miss.loc[sge_miss['AApos'].isin(list(range(425, 546)))] #ARD missense variants only\n",
    "    sge_brct = sge_miss.loc[sge_miss['AApos'].isin(list(range(568, 778)))] #BRCT missense variants only \n",
    "    sge_structured = sge_miss.loc[~(sge_miss['AApos'].isin(not_domain_coords))] #All structured missense variants only\n",
    "        \n",
    "    sge_dict = {'miss': sge_miss, 'all': sge_all, 'ring': sge_ring,\n",
    "                'ard': sge_ard, 'brct': sge_brct, 'structured': sge_structured\n",
    "               }\n",
    "    '''\n",
    "    \n",
    "    not_domain_coords =  list(range(1, 26))  + list(range(546, 568)) + list(range(123, 425)) #Positions not in a domain\n",
    "    x4_idr = list(range(123, 425)) #X4 IDR \n",
    "    sge_ring = sge_miss.loc[sge_miss['AApos'].isin(list(range(26,123)))] #RING missense variants only\n",
    "    sge_ard = sge_miss.loc[sge_miss['AApos'].isin(list(range(425, 546)))] #ARD missense variants only\n",
    "    sge_brct = sge_miss.loc[sge_miss['AApos'].isin(list(range(568, 778)))] #BRCT missense variants only\n",
    "    sge_idr = sge_miss.loc[sge_miss['AApos'].isin(x4_idr)] #X3 IDR missense variants onlly\n",
    "    sge_ptv = sge.loc[sge['Consequence'].isin(['stop_gained'])]\n",
    "\n",
    "    sge_structured = sge_miss.loc[~(sge_miss['AApos'].isin(not_domain_coords))] #All structured missense variants only\n",
    "        \n",
    "    sge_dict = {'miss': sge_miss,  'ring': sge_ring,\n",
    "                'ard': sge_ard, 'brct': sge_brct, 'structured': sge_structured,\n",
    "                'idr': sge_idr, 'ptv': sge_ptv\n",
    "               } #Final datadict\n",
    "\n",
    "    sge_keys = list(sge_dict.keys()) #Gets keys\n",
    "\n",
    "    return sge_dict, sge_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_carriers_data(cc): #Reads CARRIERS data\n",
    "    \n",
    "    cc = pd.read_excel(cc) #Reads case-control data\n",
    "    cc_all_raw = cc[cc['CAVA_GENE'].isin(['BARD1'])] #Filters only for BARD1\n",
    "    cc_all_raw = cc_all_raw.copy() #Raw df for all variants\n",
    "    cc_pop_raw = cc_all_raw[cc_all_raw['CARRIERS_PROJECT'].isin(['population-based'])] #Raw df for population-based variants only\n",
    "\n",
    "    raw_dfs = [cc_all_raw, cc_pop_raw] #Makes list for iteration\n",
    "\n",
    "    processed_dfs = []\n",
    "    for cc in raw_dfs: #Iterates through each df and generates a pos_id column for merging with SGE data\n",
    "        cc = cc[['Classification', '#CHROM', 'REF', 'ALT', 'CAVA_GENE', 'CAVA_CSN', 'CAVA_SO', 'Sample_AAF', 'Sample_ID', 'CaseControl','ER_status1', 'hg38_start']].copy() #Keeps necessary columns\n",
    "        \n",
    "        cc['pos_id'] = None #Creates emtpy pos_id column\n",
    "        cc = cc[cc['ALT'].str.len() == 1].copy()\n",
    "        cc['hg38_start'] = cc['hg38_start'].astype(str) #Sets hg38 coordinates as str data type\n",
    "        cc['pos_id'] = cc['hg38_start'] + ':' + cc['ALT'] #Creates position ID\n",
    "\n",
    "        processed_dfs.append(cc)\n",
    "\n",
    "    #All variants and population-based variants extracted\n",
    "    cc_all = processed_dfs[0]\n",
    "    cc_pop = processed_dfs[1]\n",
    "\n",
    "\n",
    "    cc_pop_er_cases = cc_pop.loc[(cc_pop['ER_status1'].isin([0,777])) & (cc_pop['CaseControl'].isin(['Case']))] #pulls ER negative variants\n",
    "    \n",
    "\n",
    "    carriers_data = {'all': cc_all,\n",
    "                     'pop': cc_pop,\n",
    "                     'cc_pop_er_cases': cc_pop_er_cases\n",
    "                    } #Data dictionary to return\n",
    "\n",
    "\n",
    "    carriers_keys = list(carriers_data.keys())\n",
    "    \n",
    "    return carriers_data, carriers_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bridges(all, population, all_ptv, pop_ptv): #Read BRIDGES Data\n",
    "\n",
    "    #Pulls BARD1 sheets\n",
    "    bridges_all = pd.read_excel(all, sheet_name = 'BARD1') \n",
    "    bridges_pop = pd.read_excel(population, sheet_name = 'BARD1')\n",
    "    bridges_all_ptv = pd.read_excel(all_ptv, sheet_name = 'BARD1')\n",
    "    bridges_pop_ptv = pd.read_excel(pop_ptv, sheet_name = 'BARD1')\n",
    "\n",
    "    raw_dfs = [bridges_all, bridges_pop, bridges_all_ptv, bridges_pop_ptv] #List for iteration\n",
    "    cleaned_dfs = []\n",
    "    \n",
    "    for df in raw_dfs: #Cleans and builds pos_id column in each df\n",
    "        df = df[['Cases', 'Controls', 'chr', 'ref', 'alt', 'hg38_pos']]\n",
    "        df = df.loc[(df['ref'].str.len() == 1) & (df['alt'].str.len() == 1)]\n",
    "        \n",
    "        df = df.rename(columns = {'hg38_pos': 'pos'})\n",
    "\n",
    "        df['pos_id'] = df['pos'].astype(str) + ':' + df['alt']\n",
    "\n",
    "        df = df[['Cases', 'Controls', 'pos_id']]\n",
    "        cleaned_dfs.append(df)\n",
    "\n",
    "\n",
    "    #Concatenates dfs for all variants and population-based variants only\n",
    "    bridges_all = pd.concat([cleaned_dfs[0], cleaned_dfs[2]])\n",
    "    bridges_pop = pd.concat([cleaned_dfs[1], cleaned_dfs[3]])\n",
    "\n",
    "    dfs = [bridges_all, bridges_pop]\n",
    "    \n",
    "    bridges_data = {'all': bridges_all,\n",
    "                    'pop': bridges_pop\n",
    "                   } #Data dicitonary to return\n",
    "\n",
    "    bridges_keys = list(bridges_data.keys())\n",
    "    \n",
    "    return bridges_data, bridges_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_carriers(carriers_data, carriers_keys, sge_data, sge_keys): #Gets counts of functionally abnormal and functionally normal variants in cases and controls\n",
    "\n",
    "    #Lists to hold values for returned dataframe\n",
    "    analysis = []\n",
    "    carrier_dataset = []\n",
    "    case_nf = []\n",
    "    control_nf = []\n",
    "    case_f = []\n",
    "    control_f = []\n",
    "    case_denom = []\n",
    "    control_denom = []\n",
    "    \n",
    "    for key in sge_keys: #Iterates through each SGE dataset\n",
    "        sge_df = sge_data[key] #Gets SGE df\n",
    "\n",
    "        for carrier_key in carriers_keys: #Iterates through each CARRIERS dataset\n",
    "            carriers_df = carriers_data[carrier_key]\n",
    "\n",
    "            merged = pd.merge(carriers_df, sge_df, on = 'pos_id', how = 'inner') #Merges case-control and SGE data\n",
    "            merged = merged.dropna(subset = ['Classification_y']) #drops any columsn without a classification\n",
    "    \n",
    "            contingency_tab = merged[['CaseControl', 'Classification_y']] #Creates dataframe for contingency table\n",
    "            contingency_tab = pd.crosstab(merged['CaseControl'], merged['Classification_y']) #Creates contingency table\n",
    "            contingency_tab = contingency_tab[contingency_tab.columns[::-1]]\n",
    "            \n",
    "            columns = list(contingency_tab.columns)\n",
    "            if 'F' not in columns:\n",
    "                contingency_tab['F'] = 0\n",
    "                \n",
    "            if key == 'ring' and carrier_key == 'cc_pop_er_cases': #Exception for ER- RING subset as there are 0 LoF variants\n",
    "                contingency_tab['NF'] = 0\n",
    "\n",
    "            if carrier_key == 'cc_pop_er_cases': #For ER- negative subsets, number of LoF vars. seen in the population-based control set is fixed\n",
    "                cases_nf = contingency_tab['NF']['Case'] #Gets number of LoF variants\n",
    "                cases_f = contingency_tab['F']['Case'] #Gets number of functionally normal variants\n",
    "                controls_nf = 19 #Number of LoF variants seen in the missense vars. only population-based control set\n",
    "                controls_f = 864  #Number of functionally normal variants seen in the missense vars. only population-based control set\n",
    "\n",
    "                analysis.append(key) #Appends SGE dataset key\n",
    "                carrier_dataset.append(carrier_key) #Appends CARRIERS data dictionary key\n",
    "                case_nf.append(cases_nf) #Appends number of LoF variants in cases\n",
    "                case_f.append(cases_f) #Appends number of functionally normal variants in cases\n",
    "                control_nf.append(controls_nf) #Appends number of LoF variants in controls \n",
    "                control_f.append(controls_f) #Appends number of functionally normal variants in controls\n",
    "            else: #Handles all other cases\n",
    "                #Gets number of LoF variants in cases and controls\n",
    "                cases_nf = contingency_tab['NF']['Case']\n",
    "                controls_nf = contingency_tab['NF']['Control']\n",
    "\n",
    "                #Gets number of functionally_normal variants in cases and controls\n",
    "                cases_f = contingency_tab['F']['Case']\n",
    "                controls_f = contingency_tab['F']['Control']\n",
    "\n",
    "                #Appends to dataframe lists\n",
    "                analysis.append(key)\n",
    "                carrier_dataset.append(carrier_key)\n",
    "                case_nf.append(cases_nf)\n",
    "                case_f.append(cases_f)\n",
    "                control_nf.append(controls_nf)\n",
    "                control_f.append(controls_f)\n",
    "\n",
    "            #Appends correct total number of individuals sequenced\n",
    "            if carrier_key == 'all':\n",
    "                case_denom.append(carriers_totals['cases_all'])\n",
    "                control_denom.append(carriers_totals['controls_all'])\n",
    "            elif carrier_key == 'pop':\n",
    "                case_denom.append(carriers_totals['cases_pop'])\n",
    "                control_denom.append(carriers_totals['controls_pop'])\n",
    "            elif carrier_key == 'cc_pop_er_cases':\n",
    "                case_denom.append(carriers_totals['er_cases'])\n",
    "                control_denom.append(carriers_totals['controls_pop'])\n",
    "\n",
    "\n",
    "    #Builds final dataframe\n",
    "    df = pd.DataFrame({'region': analysis,\n",
    "                       'dataset': carrier_dataset,\n",
    "                        'case_nf': case_nf,\n",
    "                        'control_nf': control_nf,\n",
    "                        'case_f': case_f,\n",
    "                        'control_f': control_f,\n",
    "                       'case_total': case_denom,\n",
    "                       'control_total': control_denom\n",
    "                      })\n",
    "\n",
    "    df['cohort'] = 'carriers' #Sets cohort identifer\n",
    "    df['full_data_id'] = df['cohort'] + '_' + df['dataset'] #Builds full data identifier linking cohort and specific dataset used\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bridges(bridges_data, bridges_keys, sge_data, sge_keys): #Analagous code as previous function but for BRIDGES datasets\n",
    "\n",
    "    region = []\n",
    "    bridges_dataset = []\n",
    "    case_nf = []\n",
    "    control_nf = []\n",
    "    case_f = []\n",
    "    control_f = []\n",
    "    case_denom = []\n",
    "    control_denom = []\n",
    "\n",
    "    for key in sge_keys:\n",
    "        sge_df = sge_data[key]\n",
    "\n",
    "        for bridge_key in bridges_keys:\n",
    "            bridges_df = bridges_data[bridge_key]\n",
    "    \n",
    "            merged = pd.merge(bridges_df, sge_df, on = 'pos_id', how = 'inner')\n",
    "\n",
    "            contingency_tab = merged.pivot_table(\n",
    "                values = ['Cases', 'Controls'],\n",
    "                index = 'Classification',\n",
    "                aggfunc = 'sum'\n",
    "            )\n",
    "\n",
    "            contingency_tab = contingency_tab.transpose()\n",
    "\n",
    "            columns = list(contingency_tab.columns)\n",
    "            if 'F' not in columns:\n",
    "                contingency_tab['F'] = 0\n",
    "                \n",
    "            cases_nf = contingency_tab['NF']['Cases']\n",
    "            controls_nf = contingency_tab['NF']['Controls']\n",
    "    \n",
    "            cases_f = contingency_tab['F']['Cases']\n",
    "            controls_f = contingency_tab['F']['Controls']\n",
    "\n",
    "            region.append(key)\n",
    "            bridges_dataset.append(bridge_key)\n",
    "            case_nf.append(cases_nf)\n",
    "            case_f.append(cases_f)\n",
    "            control_nf.append(controls_nf)\n",
    "            control_f.append(controls_f)\n",
    "\n",
    "            if bridge_key == 'all':\n",
    "                case_denom.append(bridges_totals['cases_all'])\n",
    "                control_denom.append(bridges_totals['controls_all'])\n",
    "            elif bridge_key == 'pop':\n",
    "                case_denom.append(bridges_totals['cases_pop'])\n",
    "                control_denom.append(bridges_totals['controls_pop'])\n",
    "\n",
    "    df = pd.DataFrame({'region': region,\n",
    "                       'dataset': bridges_dataset,\n",
    "                        'case_nf': case_nf,\n",
    "                        'control_nf': control_nf,\n",
    "                        'case_f': case_f,\n",
    "                        'control_f': control_f,\n",
    "                       'case_total': case_denom,\n",
    "                       'control_total': control_denom\n",
    "                      })\n",
    "\n",
    "    df['cohort'] = 'bridges'\n",
    "    df['full_data_id'] = df['cohort'] + '_' + df['dataset']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odds_testing(row): #Custom function to do odds ratio testing\n",
    "\n",
    "    #Extracts variant counts\n",
    "    case_nf_count = row['case_nf']\n",
    "    control_nf_count = row['control_nf']\n",
    "    case_f_count = row['case_f']\n",
    "    control_f_count = row['control_f']\n",
    "\n",
    "    #Extracts total individauls sequenced\n",
    "    case_total = row['case_total']\n",
    "    control_total = row['control_total']\n",
    "\n",
    "    #Builds array for LoF variants\n",
    "    nf_array = np.array([[case_nf_count, case_total],\n",
    "                        [control_nf_count, control_total]])\n",
    "\n",
    "    #Builds array for functionally normal variants\n",
    "    f_array = np.array([[case_f_count, case_total],\n",
    "                        [control_f_count, control_total]])\n",
    "\n",
    "\n",
    "    oddsratio, nf_p_value = stats.fisher_exact(nf_array) #Tabulates odds-ratio and p-value from Fischer's exact test\n",
    "    nf_table = sm.stats.Table2x2(nf_array) #Generates confidence intervals\n",
    "\n",
    "    #Gets stats for LoF array\n",
    "    nf_or = nf_table.oddsratio\n",
    "    nf_lwr_ci = nf_table.oddsratio_confint()[0]\n",
    "    nf_upper_ci = nf_table.oddsratio_confint()[1]\n",
    "    nf_p_val = nf_p_value\n",
    "\n",
    "    oddsratio, f_p_value = stats.fisher_exact(f_array) #Tabulates odds-ratio and p-value from Fischer's exact test\n",
    "    f_table = sm.stats.Table2x2(f_array) #Generates confidence intervals\n",
    "\n",
    "    #Gets stats for functionally normal array\n",
    "    f_or = f_table.oddsratio\n",
    "    f_lwr_ci = f_table.oddsratio_confint()[0]\n",
    "    f_upper_ci = f_table.oddsratio_confint()[1]\n",
    "    f_p_val = f_p_value\n",
    "\n",
    "    return nf_or, nf_lwr_ci, nf_upper_ci, nf_p_val, f_or, f_lwr_ci, f_upper_ci, f_p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_odds_plot(df): #Builds vizualization\n",
    "\n",
    "    df = df.loc[(df['dataset'].isin(['cc_pop_er_cases'])) | (df['full_data_id'].isin(['carriers_pop+bridges_pop', 'carriers_pop', 'bridges_pop']))]\n",
    "    df = df.loc[~(df['region'].isin(['miss','idr']))]\n",
    "\n",
    "    df['region_data_id'] = df['region'] + '_' + df['full_data_id']\n",
    "\n",
    "    label_dict = {'ring_carriers_pop': 'CARRIERS RING Mis.',\n",
    "                  'ring_carriers_cc_pop_er_cases': 'CARRIERS (ER-) RING Mis.',\n",
    "                  'ard_carriers_pop': 'CARRIERS ARD Mis.',\n",
    "                  'ard_carriers_cc_pop_er_cases': 'CARRIERS (ER-) ARD Mis.',\n",
    "                  'brct_carriers_pop': 'CARRIERS BRCT Mis.',\n",
    "                  'brct_carriers_cc_pop_er_cases': 'CARRIERS (ER-) BRCT Mis.',\n",
    "                  'structured_carriers_pop': 'CARRIERS Structured Mis.',\n",
    "                  'structured_carriers_cc_pop_er_cases': 'CARRIERS (ER-) Structured Mis.',\n",
    "                  'ring_bridges_pop': 'BRIDGES RING Mis.',\n",
    "                  'ard_bridges_pop': 'BRIDGES ARD Mis.',\n",
    "                   'brct_bridges_pop': 'BRIDGES BRCT Mis.',\n",
    "                  'structured_bridges_pop': 'BRIDGES Structured Mis.',\n",
    "                  'ard_carriers_pop+bridges_pop': 'BRIDGES + CARRIERS ARD Mis.',\n",
    "                  'brct_carriers_pop+bridges_pop': 'BRIDGES + CARRIERS BRCT Mis.',\n",
    "                  'ring_carriers_pop+bridges_pop': 'BRIDGES + CARRIERS RING Mis.',\n",
    "                  'structured_carriers_pop+bridges_pop': 'BRIDGES + CARRIERS Structured Mis.',\n",
    "                  'ptv_carriers_pop': 'CARRIERS PTV',\n",
    "                  'ptv_carriers_cc_pop_er_cases': 'CARRIERS (ER-) PTV',\n",
    "                  'ptv_bridges_pop': 'BRIDGES PTV',\n",
    "                  'ptv_carriers_pop+bridges_pop': 'BRIDGES + CARRIERS PTV'\n",
    "                 }\n",
    "\n",
    "    df['labels'] = df['region_data_id'].map(label_dict)\n",
    "    df = df.loc[~df['labels'].isin(['CARRIERS (ER-) RING Mis.'])]\n",
    "                  \n",
    "                  \n",
    "    sort_order = ['BRIDGES + CARRIERS PTV', 'BRIDGES PTV', 'CARRIERS PTV', 'CARRIERS (ER-) PTV',\n",
    "                  'BRIDGES + CARRIERS Structured Mis.', 'BRIDGES Structured Mis.', 'CARRIERS Structured Mis.','CARRIERS (ER-) Structured Mis.',\n",
    "                  'BRIDGES + CARRIERS RING Mis.', 'BRIDGES RING Mis.','CARRIERS RING Mis.','CARRIERS (ER-) RING Mis.',\n",
    "                  'BRIDGES + CARRIERS ARD Mis.', 'BRIDGES ARD Mis.', 'CARRIERS ARD Mis.', 'CARRIERS (ER-) ARD Mis.',\n",
    "                  'BRIDGES + CARRIERS BRCT Mis.', 'BRIDGES BRCT Mis.', 'CARRIERS BRCT Mis.','CARRIERS (ER-) BRCT Mis.'\n",
    "                 ]\n",
    "\n",
    "\n",
    "\n",
    "    palette = [\n",
    "    '#61ade6', # RING\n",
    "    '#8bb38b', # ARD\n",
    "    '#f2a364', # BRCT \n",
    "    '#989898',\n",
    "    'black',\n",
    "    ]\n",
    "\n",
    "\n",
    "    domains = [\n",
    "        'ring',\n",
    "        'ard',\n",
    "        'brct',\n",
    "        'structured',\n",
    "        'ptv'\n",
    "    ]\n",
    "\n",
    "\n",
    "    base = alt.Chart(df)\n",
    "    points = base.mark_point(\n",
    "        filled = True,\n",
    "        size = 50, \n",
    "        color = 'black'\n",
    "        ).encode(\n",
    "        y = alt.Y('labels:O',\n",
    "                  scale = alt.Scale(domain = sort_order),\n",
    "                 axis = alt.Axis(title = '',\n",
    "                                 labelFontSize = 16, \n",
    "                                 labelLimit = 1000\n",
    "                                )\n",
    "                 ),\n",
    "        x = alt.X('nf_or',\n",
    "                 axis = alt.Axis(\n",
    "                     title = 'Odds Ratio',\n",
    "                     labelFontSize = 16,\n",
    "                     titleFontSize = 18,\n",
    "                     values = list(range(0, 14, 2))\n",
    "                                 ),\n",
    "                  scale = alt.Scale(domain = [0, 8]\n",
    "                                   )\n",
    "                 ),\n",
    "        color = alt.Color('region',\n",
    "                           scale = alt.Scale(\n",
    "                               range = palette,\n",
    "                               domain = domains\n",
    "                           ),\n",
    "                          legend = None\n",
    "                          ),\n",
    "                           \n",
    "        tooltip = ['nf_or']\n",
    "        )\n",
    "    \n",
    "    ci_bars = base.mark_errorbar().encode(\n",
    "        y = 'labels',\n",
    "        x = alt.Y('nf_lwr_ci:Q', axis = alt.Axis(title = '')),\n",
    "        x2 = 'nf_upper_ci:Q',\n",
    "        color = alt.Color('region',\n",
    "                          scale = alt.Scale(\n",
    "                              range = palette,\n",
    "                              domain = domains\n",
    "                          )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    line = alt.Chart(pd.DataFrame({'nf_or': [1]})).mark_rule(color = 'red').encode(\n",
    "        x = 'nf_or')\n",
    "\n",
    "\n",
    "    plot = (points + ci_bars + line).configure_view(\n",
    "        stroke = None\n",
    "        ).configure_axis(\n",
    "        grid = False\n",
    "        ).interactive()\n",
    "\n",
    "    \n",
    "    plot.display()\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sge_data, sge_keys = read_sge(sge)\n",
    "    carriers_data, carriers_keys = read_carriers_data(carriers)\n",
    "    bridges_data, bridges_keys = read_bridges(bridges_all, bridges_population, bridges_all_ptv, bridges_pop_ptv)\n",
    "    carriers_counted = count_carriers(carriers_data, carriers_keys, sge_data, sge_keys)\n",
    "    bridges_counted = count_bridges(bridges_data, bridges_keys, sge_data, sge_keys)\n",
    "\n",
    "    df = pd.concat([carriers_counted, bridges_counted]).reset_index(drop = True) #Counted data frames concatenated\n",
    "    \n",
    "    to_combo = df.loc[~df['dataset'].isin(['cc_pop_er_cases'])] #ER- rows dropped\n",
    "\n",
    "    #Combines CARRIERS and BRIDGES datasets into new columns\n",
    "    combo = to_combo.groupby(['region', 'dataset']).agg({\n",
    "        'case_nf': 'sum',\n",
    "        'control_nf': 'sum',\n",
    "        'case_f': 'sum',\n",
    "        'control_f': 'sum',\n",
    "        'case_total': 'sum',\n",
    "        'control_total': 'sum',\n",
    "        'cohort': lambda x: '+'.join(x),\n",
    "        'full_data_id': lambda x: '+'.join(x)\n",
    "    }).reset_index()\n",
    "    \n",
    "    final_df = pd.concat([df, combo]).reset_index(drop = True) #Concatenated to end of original dataframe\n",
    "\n",
    "    final_df[['nf_or', 'nf_lwr_ci', 'nf_upper_ci', 'nf_p', 'f_or', 'f_lwr_ci', 'f_upper_ci', 'f_p']] = final_df.apply(odds_testing, axis = 1, result_type = 'expand') #Odds ratios calculated\n",
    "\n",
    "    final_df['significant'] = 'FALSE' #Builds significance column\n",
    "\n",
    "    final_df.loc[(final_df['nf_p'] < 0.05) & (final_df['nf_lwr_ci'] > 1) & (final_df['f_lwr_ci'] < 1), 'significant'] = 'TRUE' #Rows where the LoF OR's lower CI does not pass 1 and p < 0.05 and functionally normal variants do not associate with disease are marked as significant\n",
    "    \n",
    "\n",
    "    or_plot = make_odds_plot(final_df)\n",
    "    \n",
    "    final_df = final_df.loc[:, ['cohort', 'dataset', 'full_data_id', 'region', 'case_nf', 'control_nf', 'case_f', 'control_f', 'case_total', 'control_total', 'nf_or', 'nf_lwr_ci', 'nf_upper_ci', 'nf_p', 'f_or',\n",
    "                                'f_lwr_ci', 'f_upper_ci', 'f_p', 'significant']] #Columns reordered for excel output\n",
    "\n",
    "    final_df['nf_or'] = final_df['nf_or'].round(2).astype(str) + ' (' + final_df['nf_lwr_ci'].round(2).astype(str) + '-' + final_df['nf_upper_ci'].round(2).astype(str) + ')' \n",
    "    final_df['f_or'] = final_df['f_or'].round(2).astype(str) + ' (' + final_df['f_lwr_ci'].round(2).astype(str) + '-' + final_df['f_upper_ci'].round(2).astype(str) + ')' \n",
    "\n",
    "\n",
    "    final_df = final_df[['cohort', 'dataset', 'region', 'case_nf', 'control_nf', 'case_f', 'control_f', 'case_total', 'control_total', 'nf_or', 'nf_p', 'f_or',\n",
    "                                 'f_p', 'significant']]\n",
    "\n",
    "    \n",
    "    final_df = final_df.rename(columns = {'cohort': 'Cohort', 'case_nf': 'Case # LoF', 'control_nf': 'Control # LoF',\n",
    "                                          'case_f': 'Case # Normal', 'control_f': 'Control # Normal', 'case_total': '# Cases Tested',\n",
    "                                          'control_total': '# Controls Tested', 'nf_or': 'LoF OR', 'nf_p': 'LoF P-value',\n",
    "                                          'f_or': 'Normal OR', 'f_p': 'Normal P-value', 'significant': 'Significant', \n",
    "                                         'dataset': 'Dataset', 'region': 'Region'}\n",
    "                                          )\n",
    "\n",
    "\n",
    "    final_df.to_excel('../Data/final_tables/BARD1_OddsRatios_table.xlsx', index = False)\n",
    "    #or_plot.save('/Users/ivan/Desktop/BARD1_draft_figs/fig_4d_NewORplot.png', ppi = 500)\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
