{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/ivan/Downloads/BARD1.snvscores.tsv' #path to SGE scores\n",
    "ref_path = '../Data/SNV_filtering_inputs/20240809_BARD1_SNVlib_ref_seqs_intron_annotated.xlsx' #path to reference sequence\n",
    "coord_file = '../Data/SNV_filtering_inputs/20250415_BARD1_filter_entry.xlsx'\n",
    "#coords = [(214809,214809500),(214797050,214797156)] #genomic coordinates for exon to make map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_coords(file):\n",
    "    df = pd.read_excel(file, sheet_name = 'targets')\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        target = df['target'][i]\n",
    "        target_start = df['start'][i]\n",
    "        target_end = df['end'][i]\n",
    "\n",
    "        start_end = (target_start, target_end)\n",
    "        full_tuple = (target, start_end)\n",
    "\n",
    "        coords.append(full_tuple)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scores(file,region): #reads scores\n",
    "    \n",
    "    data = pd.read_csv(file, sep = '\\t')\n",
    "    data = data.rename(columns = {'simplified_consequence': 'Consequence', 'score': 'snv_score_minmax'})\n",
    "    data['pos'] = data['pos'].astype(str)\n",
    "    data['pos_id'] = data['pos'] + ':' + data['allele']\n",
    "    \n",
    "    data = data[['exon','target','pos', 'pos_id', 'Consequence', 'snv_score_minmax', 'amino_acid_change', 'functional_consequence']]\n",
    "    data = data.loc[data['target'].isin([region])]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference(ref, coords,region): #pulls out reference sequence\n",
    "    start, end = coords\n",
    "\n",
    "    list_coords = []\n",
    "    for i in range(start, end + 1):\n",
    "        list_coords.append(i)\n",
    "    \n",
    "    ref = pd.read_excel(ref)\n",
    "    ref = ref.loc[ref['target'].isin([region])]\n",
    "    ref = ref[['target', 'Reference', 'pos']]\n",
    "    x_coord = ref.loc[ref['pos'].isin(list_coords)]\n",
    "    \n",
    "    return x_coord\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reverse_complement(seq_string):\n",
    "    reverse_seq = seq_string[::-1]\n",
    "    reverse_comp_list = []\n",
    "    for char in reverse_seq:\n",
    "        if char == \"A\":\n",
    "            reverse_comp_list.append(\"T\")\n",
    "        elif char == \"G\":\n",
    "            reverse_comp_list.append(\"C\")\n",
    "        elif char == \"C\":\n",
    "            reverse_comp_list.append(\"G\")\n",
    "        else:\n",
    "            reverse_comp_list.append(\"A\")\n",
    "    reverse_compliment_str = \"\".join(reverse_comp_list)\n",
    "    return reverse_compliment_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reverse_comp_ref(x_ref): #reverse complements reference for antisense gene\n",
    "\n",
    "    ref_list = x_ref['Reference'].tolist()\n",
    "    ref_string = ''.join(ref_list)\n",
    "\n",
    "    reversed = reverse_complement(ref_string)\n",
    "\n",
    "    reversed_ref = []\n",
    "    for char in reversed:\n",
    "        reversed_ref.append(char)\n",
    "\n",
    "    x_ref = x_ref[::-1].reset_index(drop = True)\n",
    "\n",
    "\n",
    "    x_ref['Reference'] = reversed_ref\n",
    "\n",
    "    x_ref_reversed = x_ref\n",
    "\n",
    "    return x_ref_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def row_enumerate_ref(ref_df): #enumerates each row for heat map and each column for the base pair number\n",
    "    ref_df['Row'] = None\n",
    "\n",
    "    ref_df.loc[ref_df['Reference'] == 'A', 'Row'] = 'A'\n",
    "    ref_df.loc[ref_df['Reference'] == 'C', 'Row'] = 'C'\n",
    "    ref_df.loc[ref_df['Reference'] == 'G', 'Row'] = 'G'\n",
    "    ref_df.loc[ref_df['Reference'] == 'T', 'Row'] = 'T'\n",
    "\n",
    "    bp_num = []\n",
    "\n",
    "    for i in range(len(ref_df)):\n",
    "        bp_num.append(i)\n",
    "\n",
    "    ref_df['Column'] = bp_num\n",
    "\n",
    "    return ref_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reverse_posid(string): #to reverse complement pos_id for antisense gene\n",
    "    split = string.split(':')\n",
    "    reversed = reverse_complement(split[1])\n",
    "\n",
    "    split[1] = reversed\n",
    "\n",
    "    reversed_id = ':'.join(split)\n",
    "    \n",
    "    return reversed_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_data(df): #groups consequence of SNVs, adds reversed IDs\n",
    "    df = df.reset_index(drop = True)\n",
    "  \n",
    "    df.loc[df['Consequence'] == 'missense_variant', 'Consequence'] = 'Missense'\n",
    "    df.loc[df['Consequence'] == 'synonymous_variant', 'Consequence'] = 'Synonymous'\n",
    "    df.loc[df['Consequence'] == 'intron_variant', 'Consequence'] = 'Intronic'\n",
    "    df.loc[(df['Consequence'] == 'stop_gained') | (df['Consequence'] == 'stop_lost') | (df['Consequence'] == 'stop_retained_variant'), 'Consequence'] = 'Stop'\n",
    "    df.loc[(df['Consequence'] == 'splice_polypyrimidine_tract_variant') |(df['Consequence'] == 'splice_region_variant') | (df['Consequence'] == 'splice_acceptor_variant') | (df['Consequence'] == 'splice_donor_region_variant') | (df['Consequence'] == 'splice_donor_5th_base_variant') | (df['Consequence'] == 'splice_donor_variant'),'Consequence'] = 'Splice Region'\n",
    "    df.loc[df['Consequence'] == '3_prime_UTR_variant', 'Consequence'] = 'UTR'\n",
    "    \n",
    "    i = 0\n",
    "    reversed_ids = []\n",
    "    while i < len(df):\n",
    "        id = df['pos_id'][i]\n",
    "        reversed_id = reverse_posid(id)\n",
    "        reversed_ids.append(reversed_id)\n",
    "        \n",
    "        i += 1\n",
    "    df['pos_id'] = reversed_ids\n",
    "\n",
    "    path_max = 0.6 #SGE scores used to create each score group\n",
    "    unchanged_max = 1.1\n",
    "    \n",
    "    i = 0 \n",
    "    while i < len(df):\n",
    "        score = df['snv_score_minmax'][i]\n",
    "        id = df['pos_id'][i]\n",
    "        if score < path_max:\n",
    "            df.loc[df['pos_id'] == id, 'Function Type'] = 'Depleted'\n",
    "        elif path_max < score < unchanged_max:\n",
    "            df.loc[df['pos_id'] == id, 'Function Type'] = 'Unchanged'\n",
    "        elif score > unchanged_max:\n",
    "            df.loc[df['pos_id'] == id, 'Function Type'] = 'Enriched'\n",
    "        i += 1\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def row_enumerate_data(df): #enumerates row in SGE data for base change\n",
    "    df['Row'] = None\n",
    "\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        \n",
    "        id = df['pos_id'][i]\n",
    "        split_id = id.split(\":\")\n",
    "        change = split_id[1]\n",
    "\n",
    "        if change == 'T':\n",
    "            df.loc[df['pos_id'] == id, 'Row'] = 'T'\n",
    "        elif change == 'A':\n",
    "            df.loc[df['pos_id'] == id, 'Row'] = 'A'\n",
    "        elif change == 'C':\n",
    "            df.loc[df['pos_id'] == id, 'Row'] = 'C'\n",
    "        elif change == 'G':\n",
    "            df.loc[df['pos_id'] == id, 'Row'] = 'G'\n",
    "        i += 1\n",
    "\n",
    "    df = df[::-1].reset_index(drop = True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_enumerate_data(df,refdf): #enumerates column for basepair that was changed\n",
    "    column_dict = {} #dictionary to store the column number for each genomic coordinate\n",
    "\n",
    "    i = 0\n",
    "    while i < len(refdf): #makes the dictionary\n",
    "        coord = refdf['pos'][i]\n",
    "        col = refdf['Column'][i]\n",
    "\n",
    "        column_dict[coord] = col\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    df['Column'] = np.nan #empty column to hold column values\n",
    "\n",
    "    j = 0\n",
    "    while j < len(df): #assigns the column values\n",
    "        id = df['pos_id'][j]\n",
    "        split = id.split(':')\n",
    "        coord = int(split[0])\n",
    "        col = column_dict[coord]\n",
    "\n",
    "        df.loc[df['pos_id'] == id, 'Column'] = col\n",
    "\n",
    "        j += 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def heatmap(data, letters,region):\n",
    "    # Filter out the cells that will display letters from the heatmap dataset\n",
    "    heatmap_data = data.merge(letters, on=['Row', 'Column'], how='left', indicator=True)\n",
    "    heatmap_data = heatmap_data[heatmap_data['_merge'] == 'left_only'].drop(columns=['Reference', '_merge'])\n",
    "    \n",
    "    # Define specific colors for background value ranges\n",
    "    color_domain = [-2.1, 0, 0.6, 1, 2]\n",
    "    color_range = ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#1a9850']\n",
    "    \n",
    "    # Define the rectangle size and spacing\n",
    "    rect_size = 15\n",
    "    spacing = 7.5\n",
    "\n",
    "    total_width = (rect_size + spacing) * len(letters) - spacing\n",
    "    total_height = (rect_size + spacing) * len(data['Row'].unique()) - spacing\n",
    "\n",
    "    target = region.split('_')\n",
    "    title_s = 'Exon ' + target[1]\n",
    "\n",
    "    #title_c = alt.Chart(pd.DataFrame({'text': [title_str]})).mark_text(\n",
    "       #align='left',\n",
    "        #baseline='middle',\n",
    "        #fontSize=20\n",
    "        #).encode(\n",
    "            #text='text:N'\n",
    "        #).properties(\n",
    "            #width=30,  # Adjust width to position the title correctly\n",
    "            #height=total_height\n",
    "        #)\n",
    "\n",
    "    # Create the background heatmap with borders\n",
    "    background = alt.Chart(heatmap_data).mark_rect(\n",
    "        width=rect_size,\n",
    "        height=rect_size,\n",
    "        strokeWidth=2\n",
    "    ).encode(\n",
    "        x=alt.X('Column:N', title='Basepair', axis=alt.Axis(labelAngle=0)),\n",
    "        y=alt.Y('Row:N', title='SNV'),\n",
    "        color=alt.Color('snv_score_minmax:Q', title='SGE Score', scale=alt.Scale(domain=color_domain, range=color_range)),\n",
    "        stroke=alt.Stroke('Consequence:N', title='Consequence', legend = alt.Legend(symbolFillColor = 'white'))\n",
    "    ).properties(\n",
    "        width= total_width,\n",
    "        height= total_height\n",
    "    )\n",
    "    \n",
    "    # Create the text overlay\n",
    "    text = alt.Chart(letters).mark_text(\n",
    "        align='center',\n",
    "        baseline='middle',\n",
    "        fontSize=14\n",
    "    ).encode(\n",
    "        x=alt.X('Column:N', title='Basepair', axis=alt.Axis(labelAngle=0)),\n",
    "        y=alt.Y('Row:N', title='SNV'),\n",
    "        text='Reference:N',\n",
    "        color=alt.value('black')\n",
    "    )\n",
    "    \n",
    "    # Combine the background and text\n",
    "    heatmap = background + text\n",
    "\n",
    "    heatmap = heatmap.properties(\n",
    "        title = title_s\n",
    "    )\n",
    "    # Display the chart\n",
    "    heatmap.show()\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_maps = []\n",
    "    coords = get_region_coords(coord_file)\n",
    "    \n",
    "    for elem in coords:\n",
    "        region, ref_coords = elem\n",
    "        data = read_scores(file,region)\n",
    "        ref = get_reference(ref_path, ref_coords, region)\n",
    "        print(ref)\n",
    "        ref_reversed = reverse_comp_ref(ref)\n",
    "        ref_enumerated = row_enumerate_ref(ref_reversed)\n",
    "        sge_data_clean = process_data(data)\n",
    "        sge_row_enumerated = row_enumerate_data(sge_data_clean)\n",
    "        sge_ready = column_enumerate_data(sge_row_enumerated, ref_enumerated)\n",
    "        map = heatmap(sge_ready, ref_enumerated,region)\n",
    "        all_maps.append(map)\n",
    "\n",
    "    i = 1\n",
    "    map_1 = all_maps[0]\n",
    "    while i < len(all_maps):\n",
    "        if i == 1:\n",
    "            joined = alt.vconcat(map_1,all_maps[1])\n",
    "        elif 1 < i < len(all_maps):\n",
    "            joined = alt.vconcat(joined,all_maps[i])\n",
    "        else:\n",
    "            joined = joined.configure_view(\n",
    "                    stroke = None\n",
    "            )\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
