{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook builds Extended Data Figs. 5b (predictor score vs. SGE) and 5c (odds ratio analysis of predictor scores). In addition to S5A and S5C, figures not published also generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False #True/False for saving figures\n",
    "\n",
    "sge_file = '../Data/final_tables/supplementary_file_1_BARD1_SGE_final_table.xlsx' #SGE data file\n",
    "\n",
    "\n",
    "#External case-control data\n",
    "carriers = '../Data/extra_data/case_control_data/CARRIERS_data/20250303_CARRIERS_data.xlsx' #carriers data\n",
    "bridges = '../Data/extra_data/case_control_data/BRIDGES_data/20250815_BRIDGES_missense_population.xlsx' #bridges population missense variants\n",
    "\n",
    "#Predictor score cutoffs for providing moderate evidence toward pathogenic or benign variant classifiations. Pulled from Bergquist et al. 2025\n",
    "cutoffs = {'MutPred2': [0.197, 0.829],\n",
    "                        'REVEL': [0.183, 0.773],\n",
    "                        'AlphaMissense': [0.099, 0.906]\n",
    "          }\n",
    "\n",
    "#Total individuals sequenced for CARRIERS and BRIDGES studies.\n",
    "#All denotes all individuals/patients sequenced by the study. 'pop' denotes the subset found in patients without considering family history of breast cancer\n",
    "carriers_totals = {'cases_all': 39553, #Total number of cases sequenced\n",
    "                   'controls_all': 35867, #Total number of controls sequenced\n",
    "                   'cases_pop': 32247, #Nubmer of cases used for population-based estimates\n",
    "                   'controls_pop': 32544, #Number of controls used for population-based estimates\n",
    "                   'er_cases': 3805 #Number of estrogen receptor (ER) negative cases used in population-based estimates\n",
    "                  }\n",
    "\n",
    "#Annotations for are same, but numbers are pulled from the BRIDGES study\n",
    "bridges_totals = {'cases_all': 60466, \n",
    "                  'controls_all': 53461,\n",
    "                  'cases_pop': 48826,\n",
    "                  'controls_pop': 50703\n",
    "                 }\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholds(file): #Gets SGE score thresholds and scores\n",
    "\n",
    "    sge_df = pd.read_excel(file, sheet_name = 'scores') #Gets scores\n",
    "    sge_df = sge_df.loc[(sge_df['var_type'].isin(['snv'])) & (~sge_df['variant_qc_flag'].isin(['WARN']))] #Filters for SNVs and removes WARN variants\n",
    "    threshold_df = pd.read_excel(file, sheet_name = 'thresholds') #Gets thresholds\n",
    "\n",
    "    thresholds = [threshold_df['min'][0], threshold_df['max'][0]] #Thresholds sent to list\n",
    "\n",
    "    sge_df = sge_df.rename(columns = {'am_score': 'AlphaMissense',\n",
    "                                    'revel_score': 'REVEL',\n",
    "                                    'cadd_score': 'CADD'\n",
    "                                   }) #predictor columns renamed for nice axis labels \n",
    "\n",
    "    return sge_df, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vep(df): #Processes and generates a summary dataframe for predictor scores\n",
    "\n",
    "    df['amino_acid'] = df['amino_acid_change'].transform(lambda x: x[:-1]) \n",
    "    df = df.loc[~df['amino_acid_change'].isin(['---'])] \n",
    "    df = df.dropna(subset = ['MutPred2'])\n",
    "\n",
    "    df = df.loc[df['max_SpliceAI'] <= 0.2]\n",
    "    summary_df = df.groupby('CDS_position').agg({\n",
    "        'amino_acid': 'first',\n",
    "        'score': 'median',\n",
    "        'AlphaMissense': 'median',\n",
    "        'CADD': 'median',\n",
    "        'REVEL': 'median',\n",
    "        'MutPred2': 'median'\n",
    "    }).reset_index()\n",
    "\n",
    "    summary_df = summary_df.rename(columns = {'am_score': 'AlphaMissense',\n",
    "                                    'revel_score': 'REVEL',\n",
    "                                    'cadd_score': 'CADD'\n",
    "                                   })\n",
    "    \n",
    "    return summary_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vep_v_sge(df, thresholds): #Creates scatter plots of a predictor score vs. SGE\n",
    "\n",
    "    palette = [\n",
    "    '#006616', # dark green,\n",
    "    '#81B4C7', # dusty blue\n",
    "    '#ffcd3a', # yellow\n",
    "    '#6AA84F', # med green\n",
    "    '#93C47D', # light green\n",
    "    '#888888', # med gray\n",
    "    '#000000', # black\n",
    "    '#1170AA', # darker blue\n",
    "    '#CFCFCF' # light gray\n",
    "    ]\n",
    "\n",
    "\n",
    "    variant_types = [\n",
    "        'synonymous_variant',\n",
    "        'missense_variant',  \n",
    "        'stop_gained',\n",
    "        'intron_variant', \n",
    "        'UTR_variant',\n",
    "        'stop_lost',\n",
    "        'start_lost',\n",
    "        'splice_site_variant', \n",
    "        'splicing_variant',\n",
    "        ]\n",
    "\n",
    "    \n",
    "    veps = ['AlphaMissense', 'REVEL', 'CADD', 'MutPred2']\n",
    "\n",
    "    miss_veps = ['AlphaMissense', 'REVEL', 'MutPred2']\n",
    "    scatters =[]\n",
    "    for vep in veps:\n",
    "        new_df = df.copy()\n",
    "        if vep in miss_veps:\n",
    "            new_df = df.loc[df['max_SpliceAI'] <= 0.2]\n",
    "            pred_thresholds = cutoffs[vep]\n",
    "\n",
    "            benign_thresh = pred_thresholds[0]\n",
    "            path_thresh = pred_thresholds[1]\n",
    "\n",
    "            \n",
    "\n",
    "        scatter = alt.Chart(new_df).mark_circle(opacity = 1).encode(\n",
    "            x = alt.X('score', \n",
    "                      axis = alt.Axis(title = 'Functional Score',\n",
    "                                      titleFontSize = 18, \n",
    "                                      labelFontSize = 16\n",
    "                                     )\n",
    "                     ),\n",
    "            y = alt.Y(f'{vep}:Q',\n",
    "                      title = vep,\n",
    "                      axis = alt.Axis(titleFontSize = 18,\n",
    "                                      labelFontSize = 16\n",
    "                                     )\n",
    "                     ),\n",
    "            color = alt.Color('consequence', \n",
    "                              scale = alt.Scale(\n",
    "                                  range = palette,\n",
    "                                  domain = variant_types\n",
    "                              ),\n",
    "                              legend = alt.Legend(\n",
    "                                  title = 'Consequence',\n",
    "                                  titleFontSize = 18,\n",
    "                                  labelFontSize = 16,\n",
    "                                  symbolOpacity = 1\n",
    "                              )\n",
    "                             ),\n",
    "            tooltip = [alt.Tooltip('pos_id', title = 'Position ID: '),\n",
    "                       alt.Tooltip('amino_acid_change', title = 'AA Sub: ')\n",
    "                      ]\n",
    "        ).interactive()\n",
    "\n",
    "        sge_nf_line = alt.Chart(pd.DataFrame({'score': [thresholds[0]]})).mark_rule(color = 'red').encode(\n",
    "        x = 'score') \n",
    "\n",
    "        sge_func_line = alt.Chart(pd.DataFrame({'score': [thresholds[1]]})).mark_rule(color = 'blue').encode(\n",
    "        x = 'score') \n",
    "\n",
    "        scatter = scatter + sge_nf_line + sge_func_line\n",
    "\n",
    "        if vep in miss_veps:\n",
    "            rectangles = pd.DataFrame({\n",
    "                'x_start': [thresholds[1]],\n",
    "                'x_end': [0.1],\n",
    "                vep: [path_thresh],\n",
    "                'y_end': [1],\n",
    "                'rect_color': ['red']\n",
    "            })\n",
    "\n",
    "            rect_layer = alt.Chart(rectangles).mark_rect(opacity=0.2).encode(\n",
    "                x='x_start:Q',\n",
    "                x2='x_end:Q',\n",
    "                y=alt.Y(f\"{vep}:Q\"),\n",
    "                y2='y_end:Q',\n",
    "                color=alt.Color('rect_color:N', scale = None)  # Use literal colors\n",
    "            )\n",
    "\n",
    "            scatter = alt.layer(rect_layer, scatter).resolve_scale(y = 'shared')\n",
    "            \n",
    "        scatters.append(scatter)\n",
    "\n",
    "\n",
    "    top_panel = scatters[0] | scatters[1] \n",
    "    bottom_panel = scatters[2] | scatters[3] \n",
    "\n",
    "    full_fig = (top_panel  & bottom_panel).configure_axis(\n",
    "        grid = False\n",
    "    ).configure_view(\n",
    "        stroke = None\n",
    "    )\n",
    "\n",
    "    full_fig.display()\n",
    "    return full_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_overpathogenicity(df):\n",
    "    veps = ['AlphaMissense', 'REVEL', 'MutPred2']\n",
    "    \n",
    "    \n",
    "    \n",
    "    for vep in veps:\n",
    "        moderate_cutoffs = cutoffs[vep]\n",
    "        moderate_plus_benign = moderate_cutoffs[0]\n",
    "        moderate_plus_path = moderate_cutoffs[1]\n",
    "\n",
    "        vep_df = df.dropna(subset = [vep]).copy()\n",
    "        vep_df = vep_df.loc[~vep_df[vep].isin(['-'])]\n",
    "        vep_df[vep] = vep_df[vep].astype(float)   \n",
    "\n",
    "        vep_df['vep_class'] = 'indeterminate'\n",
    "\n",
    "        vep_df.loc[vep_df[vep] <= moderate_plus_benign, 'vep_class'] = 'functionally_normal'\n",
    "        vep_df.loc[vep_df[vep] >= moderate_plus_path, 'vep_class'] = 'functionally_abnormal'\n",
    "\n",
    "        vep_moderate_plus = vep_df['vep_class'].value_counts().get('functionally_normal', 0)\n",
    "        sge_path = vep_df['functional_consequence'].value_counts().get('functionally_normal', 0)\n",
    "\n",
    "        # a: both say normal\n",
    "        a = ((vep_df['vep_class'] == 'functionally_normal') & \n",
    "             (vep_df['functional_consequence'] == 'functionally_normal')).sum()\n",
    "        \n",
    "        # b: VEP says normal, SGE says abnormal\n",
    "        b = ((vep_df['vep_class'] == 'functionally_normal') & \n",
    "             (vep_df['functional_consequence'] == 'functionally_abnormal')).sum()\n",
    "        \n",
    "        # c: VEP says abnormal, SGE says normal\n",
    "        c = ((vep_df['vep_class'] == 'functionally_abnormal') & \n",
    "             (vep_df['functional_consequence'] == 'functionally_normal')).sum()\n",
    "        \n",
    "        # d: both say abnormal\n",
    "        d = ((vep_df['vep_class'] == 'functionally_abnormal') & \n",
    "             (vep_df['functional_consequence'] == 'functionally_abnormal')).sum()\n",
    "\n",
    "        print(vep)\n",
    "        print(f' VEP #Vars. with moderate+ path but normal in SGE: {c}')\n",
    "        print(f' VEP %Vars. with moderate+ path but normal in SGE: {(c/len(vep_df)) * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_across_gene(df): #Builds plot of predictor score across BARD1\n",
    "\n",
    "    palette = [\n",
    "    '#006616', # dark green,\n",
    "    '#81B4C7', # dusty blue\n",
    "    '#ffcd3a', # yellow\n",
    "    '#6AA84F', # med green\n",
    "    '#93C47D', # light green\n",
    "    '#888888', # med gray\n",
    "    '#000000', # black\n",
    "    '#1170AA', # darker blue\n",
    "    '#CFCFCF' # light gray\n",
    "    ]\n",
    "\n",
    "\n",
    "    variant_types = [\n",
    "        'synonymous_variant',\n",
    "        'missense_variant',  \n",
    "        'stop_gained',\n",
    "        'intron_variant', \n",
    "        'UTR_variant',\n",
    "        'stop_lost',\n",
    "        'start_lost',\n",
    "        'splice_site_variant', \n",
    "        'splicing_variant',\n",
    "        ]\n",
    "\n",
    "    df = df.rename(columns = {'score': 'SGE'})\n",
    "    \n",
    "    veps = ['SGE', 'AlphaMissense', 'REVEL', 'CADD', 'MutPred2']\n",
    "    miss_veps = ['AlphaMissense', 'REVEL', 'MutPred2']\n",
    "    plots = []\n",
    "    for vep in veps:\n",
    "        new_df = df.copy()\n",
    "        if vep in miss_veps:\n",
    "            new_df = df.loc[df['max_SpliceAI'] <= 0.2]\n",
    "        plot = alt.Chart(new_df).mark_circle().encode(\n",
    "            x = alt.X('CDS_position:Q',\n",
    "                      title = 'CDS Position'\n",
    "                     ),\n",
    "            y = f'{vep}:Q', \n",
    "            color = alt.Color('consequence:N',\n",
    "                              scale = alt.Scale(\n",
    "                                  range = palette,\n",
    "                                  domain = variant_types\n",
    "                              )\n",
    "                             ),\n",
    "            tooltip = [alt.Tooltip('amino_acid_change', title = 'AA Change: ')]\n",
    "        ).properties(\n",
    "            width = 1750,\n",
    "            height = 200\n",
    "        )\n",
    "\n",
    "        plots.append(plot)\n",
    "\n",
    "\n",
    "    full_fig = (plots[0] & plots[1] & plots[2] & plots[3] & plots[4]).configure_axis(\n",
    "        grid = False\n",
    "    ).configure_view(\n",
    "        stroke = None\n",
    "    )\n",
    "\n",
    "    full_fig.display()\n",
    "\n",
    "    return full_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(df): #Builds plot that displays points where predictor classifications (based on Bergquist thresholds) disagree with SGE\n",
    "    \n",
    "    df = df.loc[~df['amino_acid_change'].isin(['---'])]\n",
    "    df = df.loc[~df['functional_consequence'].isin(['indeterminate'])]\n",
    "    df['amino_acid'] = df['amino_acid_change'].transform(lambda x: x[:-1])\n",
    "\n",
    "    df['amino_acid_position'] = df['amino_acid'].transform(lambda x: int(x[1::]))\n",
    "    \n",
    "    df = df.dropna(subset = ['MutPred2'])\n",
    "\n",
    "    df = df.loc[df['max_SpliceAI'] <= 0.2]\n",
    "\n",
    "    predictors = ['AlphaMissense', 'MutPred2', 'REVEL']\n",
    "\n",
    "    plots = []\n",
    "    for predictor in predictors:\n",
    "        pred_thresholds = cutoffs[predictor]\n",
    "\n",
    "        benign_thresh = pred_thresholds[0]\n",
    "        path_thresh = pred_thresholds[1]\n",
    "\n",
    "        consequence_column = f'{predictor}_consequence'\n",
    "\n",
    "        df[consequence_column] = 'indeterminate'\n",
    "        #df[predictor] = df[predictor].astype(float)\n",
    "        df.loc[df[predictor] <= benign_thresh, consequence_column] = 'functionally_normal'\n",
    "        df.loc[df[predictor] >= path_thresh, consequence_column] = 'functionally_abnormal'\n",
    "\n",
    "        test_column = f'{predictor}_test'\n",
    "\n",
    "        df[test_column] = 'pred_indeterminate'\n",
    "        df.loc[df['functional_consequence'] == df[consequence_column], test_column] = 'pred_concordant'\n",
    "        df.loc[(df[consequence_column] == 'functionally_abnormal') & (df['functional_consequence'] == 'functionally_normal'), test_column]  = 'pred_overpath'\n",
    "        df.loc[(df[consequence_column] == 'functionally_normal') & (df['functional_consequence'] == 'functionally_abnormal'), test_column]  = 'pred_overbenign'\n",
    "\n",
    "        df = df.loc[~df[test_column].isin(['pred_concordant', 'pred_indeterminate'])]\n",
    "        chart = alt.Chart(df).mark_circle().encode(\n",
    "            x = 'amino_acid_position:Q',\n",
    "            y = predictor,\n",
    "            color = test_column\n",
    "        ).properties(\n",
    "            width = 1750, \n",
    "            height = 200\n",
    "        )\n",
    "\n",
    "        plots.append(chart)\n",
    "\n",
    "    final_plot = (plots[0] & plots[1] & plots[2]).resolve_scale(\n",
    "        x = 'shared'\n",
    "    )\n",
    "\n",
    "    final_plot.display()\n",
    "    #df = df[['amino_acid_position', 'AlphaMissense_consequence', 'REVEL_consequence', 'MutPred2_consequence']]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_heatmap(df, threshold): #Creates mini-heatmap across BARD1 of missense predictors and SGE\n",
    "\n",
    "    df = df.drop(columns = ['CADD'])\n",
    "    \n",
    "    vep_df = pd.melt(df, id_vars = ['CDS_position', 'amino_acid'], value_vars = ['AlphaMissense', 'REVEL', 'MutPred2'])\n",
    "\n",
    "    #sge_df = sge_df.rename(columns = {'score': 'SGE Score'})\n",
    "    \n",
    "    sge_df = pd.melt(df, id_vars = ['CDS_position', 'amino_acid'], value_vars = ['score'])\n",
    "\n",
    "    sge_df['variable'] = 'SGE'\n",
    "\n",
    "    dfs = [vep_df, sge_df]\n",
    "\n",
    "    maps = []\n",
    "\n",
    "    vep_map = alt.Chart(vep_df).mark_rect().encode(\n",
    "        x = alt.X('CDS_position:Q',\n",
    "                  title = 'CDS Position',\n",
    "                  bin = alt.Bin(maxbins = 2335, minstep = 1),\n",
    "                  axis = alt.Axis(labelFontSize = 16,\n",
    "                          values = list(range(0, 2335, 100))\n",
    "                                 )\n",
    "                 ),\n",
    "        y = alt.Y('variable:O',\n",
    "                  axis = alt.Axis(labelFontSize = 16),\n",
    "                  title = ''\n",
    "                 ),\n",
    "        color = alt.Color('value:Q',\n",
    "                          scale = alt.Scale(\n",
    "                              domain = [0,1],\n",
    "                              reverse = False,\n",
    "                              scheme = 'bluepurple'\n",
    "                          ),\n",
    "                          legend = alt.Legend(\n",
    "                              title = 'Median VEP Score',\n",
    "                              titleFontSize = 18,\n",
    "                              labelFontSize = 16,\n",
    "                              gradientLength = 100\n",
    "                          )\n",
    "                         ),\n",
    "        tooltip = [alt.Tooltip('CDS_position', title = 'CDS Pos: '), \n",
    "                  alt.Tooltip('amino_acid', title = 'Amino Acid: '),\n",
    "                  alt.Tooltip('value', title = 'Min. Score')\n",
    "                  ]\n",
    "    ).properties(\n",
    "        width = 1750,\n",
    "        height = 300\n",
    "    )\n",
    "\n",
    "    maps.append(vep_map)\n",
    "\n",
    "    sge_map = alt.Chart(sge_df).mark_rect().encode(\n",
    "        x = alt.X('CDS_position:Q',\n",
    "                  title = 'CDS Position',\n",
    "                  bin = alt.Bin(maxbins = 2335, minstep = 1),\n",
    "                  axis = alt.Axis(labelFontSize = 16,\n",
    "                                  values = list(range(0, 2335, 100))\n",
    "                                 )\n",
    "                 ),\n",
    "        y = alt.Y('variable:O',\n",
    "                  title = '',\n",
    "                  axis = alt.Axis(labelFontSize = 16)\n",
    "                 ),\n",
    "        color = alt.Color('value:Q',scale = alt.Scale(\n",
    "                                  domain = [-0.2, 0],\n",
    "                                  clamp = True,\n",
    "                                  reverse = True,\n",
    "                                  scheme = 'bluepurple'\n",
    "                              ),\n",
    "                          legend = alt.Legend(title = 'Median Functional Score',\n",
    "                                             titleFontSize = 18,\n",
    "                                             labelFontSize = 16, \n",
    "                                             gradientLength = 100)\n",
    "                         ),\n",
    "        tooltip = [alt.Tooltip('CDS_position', title = 'CDS Pos: '), \n",
    "                  alt.Tooltip('amino_acid', title = 'Amino Acid: '),\n",
    "                  alt.Tooltip('value', title = 'Min. Score')\n",
    "                  ]\n",
    "    ).properties(\n",
    "        width = 1750,\n",
    "        height = 300\n",
    "    )\n",
    "\n",
    "    maps.append(sge_map)\n",
    "    \n",
    "    final_map = (alt.layer(maps[0], maps[1])).resolve_scale(\n",
    "        color = 'independent'\n",
    "    ).properties(\n",
    "        title = 'Median Predictor Score vs. Median Missense Functional Score'\n",
    "    )\n",
    "\n",
    "    final_map.display()\n",
    "    \n",
    "    return final_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def odds_testing(row): #Custom function to do odds ratio testing\n",
    "\n",
    "    #Extracts variant counts\n",
    "    case_nf_count = row['case_nf']\n",
    "    control_nf_count = row['control_nf']\n",
    "    case_f_count = row['case_f']\n",
    "    control_f_count = row['control_f']\n",
    "\n",
    "    #Extracts total individauls sequenced\n",
    "    case_total = row['case_total']\n",
    "    control_total = row['control_total']\n",
    "\n",
    "    #Builds array for LoF variants\n",
    "    nf_array = np.array([[case_nf_count, case_total],\n",
    "                        [control_nf_count, control_total]])\n",
    "\n",
    "    #Builds array for functionally normal variants\n",
    "    f_array = np.array([[case_f_count, case_total],\n",
    "                        [control_f_count, control_total]])\n",
    "\n",
    "\n",
    "    oddsratio, nf_p_value = stats.fisher_exact(nf_array) #Tabulates odds-ratio and p-value from Fischer's exact test\n",
    "    nf_table = sm.stats.Table2x2(nf_array) #Generates confidence intervals\n",
    "\n",
    "    #Gets stats for LoF array\n",
    "    nf_or = nf_table.oddsratio\n",
    "    nf_lwr_ci = nf_table.oddsratio_confint()[0]\n",
    "    nf_upper_ci = nf_table.oddsratio_confint()[1]\n",
    "    nf_p_val = nf_p_value\n",
    "\n",
    "    oddsratio, f_p_value = stats.fisher_exact(f_array) #Tabulates odds-ratio and p-value from Fischer's exact test\n",
    "    f_table = sm.stats.Table2x2(f_array) #Generates confidence intervals\n",
    "\n",
    "    #Gets stats for functionally normal array\n",
    "    f_or = f_table.oddsratio\n",
    "    f_lwr_ci = f_table.oddsratio_confint()[0]\n",
    "    f_upper_ci = f_table.oddsratio_confint()[1]\n",
    "    f_p_val = f_p_value\n",
    "\n",
    "    return nf_or, nf_lwr_ci, nf_upper_ci, nf_p_val, f_or, f_lwr_ci, f_upper_ci, f_p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def case_control(df): #Wrapper function for case-control analysis\n",
    "    \n",
    "    sge_data = {}\n",
    "    sge_data['mis'] = df\n",
    "\n",
    "    sge_keys = ['mis']\n",
    "    def read_carriers_data(cc): #Reads CARRIERS data\n",
    "    \n",
    "        cc = pd.read_excel(cc) #Reads case-control data\n",
    "        cc_all_raw = cc[cc['CAVA_GENE'].isin(['BARD1'])] #Filters only for BARD1\n",
    "        cc_all_raw = cc_all_raw.copy() #Raw df for all variants\n",
    "        cc_pop_raw = cc_all_raw[cc_all_raw['CARRIERS_PROJECT'].isin(['population-based'])] #Raw df for population-based variants only\n",
    "    \n",
    "        raw_dfs = [cc_all_raw, cc_pop_raw] #Makes list for iteration\n",
    "    \n",
    "        processed_dfs = []\n",
    "        for cc in raw_dfs: #Iterates through each df and generates a pos_id column for merging with SGE data\n",
    "            cc = cc[['Classification', '#CHROM', 'REF', 'ALT', 'CAVA_GENE', 'CAVA_CSN', 'CAVA_SO', 'Sample_AAF', 'Sample_ID', 'CaseControl','ER_status1', 'hg38_start']].copy() #Keeps necessary columns\n",
    "            \n",
    "            cc['pos_id'] = None #Creates emtpy pos_id column\n",
    "            cc = cc[cc['ALT'].str.len() == 1].copy()\n",
    "            cc['hg38_start'] = cc['hg38_start'].astype(str) #Sets hg38 coordinates as str data type\n",
    "            cc['pos_id'] = cc['hg38_start'] + ':' + cc['ALT'] #Creates position ID\n",
    "    \n",
    "            processed_dfs.append(cc)\n",
    "    \n",
    "        #All variants and population-based variants extracted\n",
    "        cc_all = processed_dfs[0]\n",
    "        cc_pop = processed_dfs[1]\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        carriers_data = {'pop': cc_pop\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "        carriers_keys = list(carriers_data.keys())\n",
    "        \n",
    "        return carriers_data, carriers_keys\n",
    "\n",
    "    def read_bridges(bridges): #Read BRIDGES Data\n",
    "\n",
    "        #Pulls BARD1 sheets\n",
    "  \n",
    "        bridges_pop = pd.read_excel(bridges, sheet_name = 'BARD1')\n",
    "\n",
    "        raw_dfs = [bridges_pop] #List for iteration\n",
    "        cleaned_dfs = []\n",
    "        \n",
    "        for df in raw_dfs: #Cleans and builds pos_id column in each df\n",
    "            df = df[['Cases', 'Controls', 'chr', 'ref', 'alt', 'hg38_pos']]\n",
    "            df = df.loc[(df['ref'].str.len() == 1) & (df['alt'].str.len() == 1)]\n",
    "            \n",
    "            df = df.rename(columns = {'hg38_pos': 'pos'})\n",
    "    \n",
    "            df['pos_id'] = df['pos'].astype(str) + ':' + df['alt']\n",
    "    \n",
    "            df = df[['Cases', 'Controls', 'pos_id']]\n",
    "            cleaned_dfs.append(df)\n",
    "    \n",
    "    \n",
    "        #Concatenates dfs for all variants and population-based variants only\n",
    "        bridges_pop = cleaned_dfs[0]\n",
    "    \n",
    "        \n",
    "        bridges_data = {\n",
    "                        'pop': bridges_pop\n",
    "                       } #Data dicitonary to return\n",
    "    \n",
    "        bridges_keys = list(bridges_data.keys())\n",
    "        \n",
    "        return bridges_data, bridges_keys\n",
    "\n",
    "    def count_carriers(carriers_data, carriers_keys, sge_data, sge_keys): #Gets counts of functionally abnormal and functionally normal variants in cases and controls\n",
    "\n",
    "        #Lists to hold values for returned dataframe\n",
    "        analysis = []\n",
    "        carrier_dataset = []\n",
    "        case_nf = []\n",
    "        control_nf = []\n",
    "        case_f = []\n",
    "        control_f = []\n",
    "        case_denom = []\n",
    "        control_denom = []\n",
    "        \n",
    "        for key in sge_keys: #Iterates through each SGE dataset\n",
    "            sge_df = sge_data[key] #Gets SGE df\n",
    "    \n",
    "            for carrier_key in carriers_keys: #Iterates through each CARRIERS dataset\n",
    "                carriers_df = carriers_data[carrier_key]\n",
    "    \n",
    "                merged = pd.merge(carriers_df, sge_df, on = 'pos_id', how = 'inner') #Merges case-control and SGE data\n",
    "                merged = merged.dropna(subset = ['Classification_y']) #drops any columsn without a classification\n",
    "                contingency_tab = merged[['CaseControl', 'Classification_y']] #Creates dataframe for contingency table\n",
    "                contingency_tab = pd.crosstab(merged['CaseControl'], merged['Classification_y']) #Creates contingency table\n",
    "                contingency_tab = contingency_tab[contingency_tab.columns[::-1]]\n",
    "                \n",
    "                columns = list(contingency_tab.columns)\n",
    "                if 'F' not in columns:\n",
    "                    contingency_tab['F'] = 0\n",
    "                    \n",
    "                if key == 'ring' and carrier_key == 'cc_pop_er_cases': #Exception for ER- RING subset as there are 0 LoF variants\n",
    "                    contingency_tab['NF'] = 0\n",
    "    \n",
    "                if carrier_key == 'cc_pop_er_cases': #For ER- negative subsets, number of LoF vars. seen in the population-based control set is fixed\n",
    "                    cases_nf = contingency_tab['NF']['Case'] #Gets number of LoF variants\n",
    "                    cases_f = contingency_tab['F']['Case'] #Gets number of functionally normal variants\n",
    "                    controls_nf = 19 #Number of LoF variants seen in the missense vars. only population-based control set\n",
    "                    controls_f = 864  #Number of functionally normal variants seen in the missense vars. only population-based control set\n",
    "    \n",
    "                    analysis.append(key) #Appends SGE dataset key\n",
    "                    carrier_dataset.append(carrier_key) #Appends CARRIERS data dictionary key\n",
    "                    case_nf.append(cases_nf) #Appends number of LoF variants in cases\n",
    "                    case_f.append(cases_f) #Appends number of functionally normal variants in cases\n",
    "                    control_nf.append(controls_nf) #Appends number of LoF variants in controls \n",
    "                    control_f.append(controls_f) #Appends number of functionally normal variants in controls\n",
    "                else: #Handles all other cases\n",
    "                    #Gets number of LoF variants in cases and controls\n",
    "                    cases_nf = contingency_tab['NF']['Case']\n",
    "                    controls_nf = contingency_tab['NF']['Control']\n",
    "    \n",
    "                    #Gets number of functionally_normal variants in cases and controls\n",
    "                    cases_f = contingency_tab['F']['Case']\n",
    "                    controls_f = contingency_tab['F']['Control']\n",
    "    \n",
    "                    #Appends to dataframe lists\n",
    "                    analysis.append(key)\n",
    "                    carrier_dataset.append(carrier_key)\n",
    "                    case_nf.append(cases_nf)\n",
    "                    case_f.append(cases_f)\n",
    "                    control_nf.append(controls_nf)\n",
    "                    control_f.append(controls_f)\n",
    "    \n",
    "                #Appends correct total number of individuals sequenced\n",
    "                if carrier_key == 'all':\n",
    "                    case_denom.append(carriers_totals['cases_all'])\n",
    "                    control_denom.append(carriers_totals['controls_all'])\n",
    "                elif carrier_key == 'pop':\n",
    "                    case_denom.append(carriers_totals['cases_pop'])\n",
    "                    control_denom.append(carriers_totals['controls_pop'])\n",
    "                elif carrier_key == 'cc_pop_er_cases':\n",
    "                    case_denom.append(carriers_totals['er_cases'])\n",
    "                    control_denom.append(carriers_totals['controls_pop'])\n",
    "    \n",
    "    \n",
    "        #Builds final dataframe\n",
    "        df = pd.DataFrame({'region': analysis,\n",
    "                           'dataset': carrier_dataset,\n",
    "                            'case_nf': case_nf,\n",
    "                            'control_nf': control_nf,\n",
    "                            'case_f': case_f,\n",
    "                            'control_f': control_f,\n",
    "                           'case_total': case_denom,\n",
    "                           'control_total': control_denom\n",
    "                          })\n",
    "    \n",
    "        df['cohort'] = 'carriers' #Sets cohort identifer\n",
    "        df['full_data_id'] = df['cohort'] + '_' + df['dataset'] #Builds full data identifier linking cohort and specific dataset used\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "    def count_bridges(bridges_data, bridges_keys, sge_data, sge_keys): #Analagous code as previous function but for BRIDGES datasets\n",
    "\n",
    "        region = []\n",
    "        bridges_dataset = []\n",
    "        case_nf = []\n",
    "        control_nf = []\n",
    "        case_f = []\n",
    "        control_f = []\n",
    "        case_denom = []\n",
    "        control_denom = []\n",
    "    \n",
    "        for key in sge_keys:\n",
    "            sge_df = sge_data[key]\n",
    "    \n",
    "            for bridge_key in bridges_keys:\n",
    "                bridges_df = bridges_data[bridge_key]\n",
    "        \n",
    "                merged = pd.merge(bridges_df, sge_df, on = 'pos_id', how = 'inner')\n",
    "                contingency_tab = merged.pivot_table(\n",
    "                    values = ['Cases', 'Controls'],\n",
    "                    index = 'Classification',\n",
    "                    aggfunc = 'sum'\n",
    "                )\n",
    "    \n",
    "                contingency_tab = contingency_tab.transpose()\n",
    "    \n",
    "                columns = list(contingency_tab.columns)\n",
    "                if 'F' not in columns:\n",
    "                    contingency_tab['F'] = 0\n",
    "                    \n",
    "                cases_nf = contingency_tab['NF']['Cases']\n",
    "                controls_nf = contingency_tab['NF']['Controls']\n",
    "        \n",
    "                cases_f = contingency_tab['F']['Cases']\n",
    "                controls_f = contingency_tab['F']['Controls']\n",
    "    \n",
    "                region.append(key)\n",
    "                bridges_dataset.append(bridge_key)\n",
    "                case_nf.append(cases_nf)\n",
    "                case_f.append(cases_f)\n",
    "                control_nf.append(controls_nf)\n",
    "                control_f.append(controls_f)\n",
    "    \n",
    "                if bridge_key == 'all':\n",
    "                    case_denom.append(bridges_totals['cases_all'])\n",
    "                    control_denom.append(bridges_totals['controls_all'])\n",
    "                elif bridge_key == 'pop':\n",
    "                    case_denom.append(bridges_totals['cases_pop'])\n",
    "                    control_denom.append(bridges_totals['controls_pop'])\n",
    "    \n",
    "        df = pd.DataFrame({'region': region,\n",
    "                           'dataset': bridges_dataset,\n",
    "                            'case_nf': case_nf,\n",
    "                            'control_nf': control_nf,\n",
    "                            'case_f': case_f,\n",
    "                            'control_f': control_f,\n",
    "                           'case_total': case_denom,\n",
    "                           'control_total': control_denom\n",
    "                          })\n",
    "    \n",
    "        df['cohort'] = 'bridges'\n",
    "        df['full_data_id'] = df['cohort'] + '_' + df['dataset']\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def wrapper():\n",
    "        carriers_data, carriers_keys = read_carriers_data(carriers)\n",
    "        bridges_data, bridges_keys = read_bridges(bridges)\n",
    "\n",
    "        carriers_counted = count_carriers(carriers_data, carriers_keys, sge_data, sge_keys)\n",
    "        bridges_counted = count_bridges(bridges_data, bridges_keys, sge_data, sge_keys)\n",
    "        \n",
    "        df = pd.concat([carriers_counted, bridges_counted]).reset_index(drop = True) #Counted data frames concatenated\n",
    "\n",
    "        #Combines CARRIERS and BRIDGES datasets into new columns\n",
    "        final_df = df.groupby(['region', 'dataset']).agg({\n",
    "            'case_nf': 'sum',\n",
    "            'control_nf': 'sum',\n",
    "            'case_f': 'sum',\n",
    "            'control_f': 'sum',\n",
    "            'case_total': 'sum',\n",
    "            'control_total': 'sum',\n",
    "            'cohort': lambda x: '+'.join(x),\n",
    "            'full_data_id': lambda x: '+'.join(x)\n",
    "        }).reset_index()\n",
    "\n",
    "        final_df[['nf_or', 'nf_lwr_ci', 'nf_upper_ci', 'nf_p', 'f_or', 'f_lwr_ci', 'f_upper_ci', 'f_p']] = final_df.apply(odds_testing, axis = 1, result_type = 'expand') #Odds ratios calculated\n",
    "        final_df['significant'] = 'FALSE' #Builds significance column\n",
    "\n",
    "        final_df.loc[(final_df['nf_p'] < 0.05) & (final_df['nf_lwr_ci'] > 1) & (final_df['f_lwr_ci'] < 1), 'significant'] = 'TRUE' #Rows where the LoF OR's lower CI does not pass 1 and p < 0.05 and functionally normal variants do not associate with disease are marked as significant\n",
    "        \n",
    "        return final_df\n",
    "        \n",
    "    odds_df = wrapper()\n",
    "\n",
    "    return odds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_plot(df): #Builds odds ratio plot\n",
    "    base = alt.Chart(df)\n",
    "\n",
    "    base_or = base.mark_point(filled = True,\n",
    "        size = 50, \n",
    "        color = 'black').encode(\n",
    "        x = alt.X('nf_or:Q', \n",
    "                  title = 'Odds Ratio'\n",
    "                 ),\n",
    "        y = alt.Y('score_set:N',\n",
    "                  title = ''\n",
    "                 )\n",
    "    )\n",
    "\n",
    "    ci_bars = base.mark_errorbar().encode(\n",
    "        y = 'score_set',\n",
    "        x = alt.X('nf_lwr_ci:Q',\n",
    "                  title = ''\n",
    "                 ),\n",
    "        x2 = 'nf_upper_ci:Q'\n",
    "    )\n",
    "\n",
    "    line = alt.Chart(pd.DataFrame({'nf_or': [1]})).mark_rule(color = 'red').encode(\n",
    "        x = 'nf_or')\n",
    "\n",
    "    plot = alt.layer(base_or, ci_bars, line).configure_axis(\n",
    "        grid = False\n",
    "    ).configure_view(\n",
    "        stroke = None\n",
    "    )\n",
    "    plot.display()\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sge_df, thresholds = get_thresholds(sge_file)\n",
    "\n",
    "\n",
    "    agg_df = process_vep(sge_df)\n",
    "    \n",
    "    scatter_plot = vep_v_sge(sge_df, thresholds)\n",
    "    quant_overpathogenicity(sge_df)\n",
    "    across_gene = scores_across_gene(sge_df)\n",
    "\n",
    "    concordance(sge_df)\n",
    "    heatmap = min_heatmap(agg_df, thresholds)\n",
    "\n",
    "    cutoffs['SGE'] = thresholds\n",
    "\n",
    "    all_scores = list(cutoffs.keys())\n",
    "\n",
    " \n",
    "    odds_dfs = []\n",
    "    print('Starting Odds Analysis...')\n",
    "    for key in all_scores:\n",
    "        print(f' Processing {key} ...')\n",
    "        if key == 'SGE':\n",
    "            sge_df = sge_df.rename(columns = {'score': 'SGE'})\n",
    "            sge_df = sge_df.loc[sge_df['consequence'].isin(['missense_variant'])]\n",
    "            \n",
    "        \n",
    "            df = sge_df[['pos_id', key, 'functional_consequence']]\n",
    "            df = df.copy()\n",
    "\n",
    "        elif key == 'REVEL' or key == 'MutPred2':\n",
    "            training_col = f'{key}_train'\n",
    "            df = sge_df[['pos_id', key, training_col]]\n",
    "            df = df.copy()\n",
    "            df = df.dropna(subset = [key])\n",
    "            df = df.loc[~df[key].isin(['-'])]\n",
    "            df = df.loc[df[training_col].isin([0.0])]\n",
    "            \n",
    "            df[key] = df[key].astype(float)\n",
    "\n",
    "        else: \n",
    "            df = sge_df[['pos_id', key]]\n",
    "            df = df.copy()\n",
    "            df = df.dropna(subset = [key])\n",
    "            df = df.loc[~df[key].isin(['-'])]\n",
    "            df[key] = df[key].astype(float)\n",
    "        \n",
    "        lwr_thresh, upper_thresh = cutoffs[key]\n",
    "        \n",
    "        df['Classification'] = 'Indeterminate'\n",
    "\n",
    "        if key == 'SGE': \n",
    "            df.loc[df['functional_consequence'] == 'functionally_abnormal', 'Classification'] = 'NF'\n",
    "            df.loc[df['functional_consequence'] == 'functionally_normal', 'Classification'] = 'F'\n",
    "\n",
    "            df = df[['pos_id', key, 'Classification']]\n",
    "        else: \n",
    "            df.loc[df[key] <= lwr_thresh, 'Classification'] = 'F'\n",
    "            df.loc[df[key] >= upper_thresh, 'Classification'] = 'NF'\n",
    "\n",
    "\n",
    "        odds_df = case_control(df)\n",
    "        odds_df['score_set'] = key\n",
    "        odds_dfs.append(odds_df)\n",
    "\n",
    "\n",
    "    final_df = pd.concat(odds_dfs).reset_index(drop = True)\n",
    "    print(final_df)\n",
    "    odds_plot = or_plot(final_df)\n",
    "\n",
    "\n",
    "    if save_figs: \n",
    "        heatmap.save('/Users/ivan/Desktop/BARD1_draft_figs/supp_figs/suppfig_vep_heatmap.svg')\n",
    "        scatter_plot.save('/Users/ivan/Desktop/BARD1_draft_figs/supp_figs/suppfig_VEPvsSGE.svg')\n",
    "        across_gene.save('/Users/ivan/Desktop/BARD1_draft_figs/supp_figs/suppfig_VEPs_AcrossBARD1.svg')\n",
    "        odds_plot.save('/Users/ivan/Desktop/BARD1_draft_figs/supp_figs/suppfig_VEPs_ORs.svg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
